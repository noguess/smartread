**Title: 清华 AGI-Next 圆桌对话：唐杰，杨强，林俊旸和姚顺雨都说了什么干货？｜华尔街现场**

**主持人（广密）：**
Hello Hello，我是接下来 Panel 的主持人广密。刚才我在台下听有几个感受。第一就是唐老师的号召力很强，清华的人才非常好，不仅是国内包括海外，清华人的比例非常高。感觉这一波好像跟隔壁学校在 AI 这一波拉开差距了。

第二就是我刚才听几个 Talk 的感受，不止 Follow，不止开源，而且都在探索自己的下个范式。而且不只是 Coding，都在探索自己的产品形态。这个时间点特别有意思，2025 年其实是中国开源模型大放异彩的一年，四家“开源四杰”在全球取得了非常大放异彩的成绩。而且是 Coding 过去一年有 10 到 20 倍增长的一年，包括海外也在提 Scaling 到底走到哪一步了，就是有没有新的范式出来了。所以今天这个活动接下来这个 Panel，我觉得要讨论接下来怎么走是特别有意思的。

接下来我们邀请几位嘉宾：杨强教授、唐杰老师、俊旸和顺雨。

我们先从第一个比较有意思的话题聊起来。硅谷的几家其实也都在明显地做分化，我觉得从分化这个主题可以先聊起来。Anthropic 其实是对中国模型公司有一个非常大的启发的，就是硅谷的竞争那么激烈，它没有完全 Follow 全都做，而是专注到了企业、专注到了 Coding、专注到 Agentic。所以我也在想，接下来中国的模型会分化成自己想要的哪些方向？我觉得分化这个主题是一个蛮有意思的。

我看顺雨也上线了，要不顺雨可以开场给大家讲一讲，包括你最近在忙什么。

**姚顺雨：**
大家好，我现在是不是一个巨大的脸在会场？不好意思，今天没法亲自来北京，但是很高兴参加这个活动。最近就忙着做模型做产品，我觉得就是做 AI 一个很正常的常态。回国感觉还是挺好的，吃的好很多。

**主持人（广密）：**
顺雨，你能展开聊聊你对模型分化这个主题的想法吗？就是说硅谷你看也都在分化，比如说 Anthropic 做了 Coding，中国的模型做了开源，过去 Coding 提得也很快，包括 Google Gemini 也没有全都做，它先把全模态这个点做得很好。你的老东家（OpenAI）在重点做 2C。我不知道，因为你是横跨中美的，这个体感可以给大家讲讲。接下来不管说自己也好，各家也好，分化这个点你是怎么思考的？

**姚顺雨：**
对，我觉得有两个大的感受。一个感受是 2C 和 2B 明显发生了分化；另一个感受就是说垂直整合这条路，以及模型和应用分层这条路，也开始出现了分化。

我先说第一点。我觉得很明显的就是，当大家想到 AI 的 Super App，现在大家想到的就是两个，一个是 ChatGPT，另一个是 Claude（或者说 Coding 类工具），大家可以认为分别是做 2C 和 2B 的典范。但是我觉得很有意思一点就是说，我们今天用 ChatGPT 的时候，其实和去年相比，对于大部分人大部分时候，感受的变化已经没有那么强烈了。但是相反，Claude Coding 可能一年前这场革命还没有开始，但是这一年夸张一点说，已经在重塑整个计算机行业做事的方式——人已经不再写代码，而是去用英语和电脑去交流。

我觉得很核心的一点就是说，对于 2C 来说，大部分人大部分时候其实不需要用到这么强的智能。可能今天用 ChatGPT 和去年相比，写抽象代数或者去做伽罗瓦理论的能力变强了，但是大部分人大部分时候感受不到。大部分人其实可能还是在——尤其在中国——更多像是一个搜索引擎的加强版，很多时候你也不知道该怎么样去用，去把它的智商给激发出来。

但是对于 2B 来说，我觉得很明显的一点就是说，智能越高很多时候就代表生产力越高，就代表你可以赚的钱越多，这些东西都相关联。那对于 2B 来说，还有一个很明显的点就是，大部分时候很多人愿意用最强的模型。可能一个模型是 200 美元一个月，第二强或者差一些的模型是 50 美元或 20 美元一个月，我们今天发现很多（起码美国的）人，是会愿意花那个溢价去用最好的模型。因为可能他的年薪是 20 万美元，他每天比如要做 10 个任务，一个像 Opus 这样非常强的模型，可能会 10 个任务里 8、9 个就直接做对了；那差的模型可能做对 5、6 个。问题在于你不知道这 5、6 个是哪 5、6 个的情况下，你就需要花很多的精力去监控这个事情。那其实我觉得无论是人还是模型，在 2B 这个市场上就发现了一个很有意思的现象：那个强的模型和稍微差一点或者弱的模型，它的分化会变得越来越明显。我觉得这是第一点观察。

然后第二点观察就是说垂直整合这条路，和模型应用分层这条路的区别。我觉得一个比较好的例子可能就是，比如 ChatGPT Agent，相对比于用 Claude 或者 Gemini 加上像 Manus 这样的应用层产品。我觉得一方面就是说，过去大家会认为当你有这个垂直整合能力，你就肯定会做得更好，但起码今天来看并不一定。首先就是说模型层和应用层需要的能力还是挺不一样的。对于尤其是对 2B 或者是生产力这样的场景来说，可能更大的预训练还是一个非常关键的事情，那这个事情可能对于产品公司确实也很难做。但是想要把这样一个特别好的模型用好，或者说这样的模型它有它的溢出能力，其实也需要在应用层或者说在环境这一层做很多相应的事情。

所以我们会发现其实在 2C 的应用上，垂直整合还是成立的，无论是 ChatGPT 还是豆包还是各种这样的 2C 的 App，模型和产品是非常紧密迭代的。但对于 2B 来说这个趋势似乎是相反的，就是说模型在变得越来越强越来越好，但是也同样会有更多应用层的东西想要去利用这样好的模型去在不同的生产力环节发挥作用。这是我的两个观察。

**主持人（广密）：**
我再 Follow 顺雨一个问题，因为你有了一个新的身份，在中国这个市场上，那你接下来的 Bet 会是什么？有哪些鲜明的特点或者关键词吗？现在能给大家 Share 的吗？

**姚顺雨：**
对，我觉得腾讯肯定还是一个 2C 基因更强的公司，所以我们会思考怎么样能够让今天的大模型或者说 AI 的发展给用户提供更多价值。但我觉得有很核心的思考就是说，我们发现很多时候我们的 Bottleneck（瓶颈）可能在 2C 这一端不是更大的模型或者更强的强化学习，很多时候可能是额外的 Context（上下文）和 Environment（环境）。

我最近经常举的一个例子，比如说我想问我今天该去吃什么。其实你今天问 ChatGPT 和去年问，或者明年问，这个事情可能都会很差。因为这个事情你想要变好，不是说你需要更大的模型、更强的预训练、更强的强化学习、更多的 Agent 环境或者更强的搜索引擎。这个问题的 Bottleneck 可能是你需要更多的额外输入或者说 Context。比如说如果它知道今天特别冷，我需要吃点暖和的，我今天在这个范围活动，可能我老婆在另一个地方，她想吃什么等等。其实回答这样的问题，更多的 Bottleneck 我觉得是额外的 Context。比如说我和老婆聊了很多时间，其实我们可以把这聊天记录从微信转发给元宝，或者说把这些额外的输入去用好的话，我觉得其实反而会给用户带来很多额外的价值。所以我觉得这是我们对 To C 上的思考。

然后我觉得做 To B 在中国确实是一个非常难的事情。这些生产力的革命，包括现在我们今天很多中国的公司做 Coding Agent 其实也是要去打海外市场。我觉得这方面的话，我们会思考怎么去把自己给先服务好。作为大公司做 Coding Agent 和创业公司的一个区别就是，大公司本身就已经有很多各种各样的应用场景，各种各样的需要生产力变得更好的地方。那如果我们的模型能够在这些地方做得更好，不仅这个模型它会有自己独特的优势，不仅我们的公司本身能得到很好的发展，我觉得很重要一点就是说，对于真实世界更 Diverse（多样化）的场景的数据的捕捉，会是一个很有意思的事情。

那比如说像 Claude、Anthropic 它是一个创业公司，包括他们想要去做更多的 Code Agent 的数据，其实就是需要通过各种数据厂商去标这些数据。然后这些数据厂商它其实是需要利用各种各样的软件工程师去想我要去标什么样的数据，怎么去做。那这个事情可能最后 Bottom-up 就是说，那你数据公司一共就这么几家，它一共就招了这么多人，它可能最终你的 Diversity 是会受限的。但是如果你是一个十万人的公司，可能会有一些有意思的尝试，怎么去真的把真实世界的数据给利用好，而不是仅仅依赖于标注商或者说 Distillation（蒸馏）。

**主持人（广密）：**
多谢顺雨。我接下来 Q 一下俊旸，你怎么看接下来通义千问未来的一个生态位或者分化的 Bet？因为你后面重点讲了那个全模态的方向，之前阿里云更多比如在 2B 很强，那接下来可能你也提了全模态可能更多 2C 的，我不知道这方面是怎么思考的。

**林俊旸：**
理论上我是不能评论公司的，但是我觉得公司也不一定有那么多基因之分，一代一代的人可能就塑造了这一些公司。比如说今年顺雨到了腾讯之后，腾讯可能就是变成一个有着顺雨基因的公司。

接下来这一句其实我也想注入一些比如说我们自己对 AGI 的理解。因为我觉得今天 2B 和 2C 也好，我们其实是在服务真实的人类，所以我们其实想的问题是应该怎么让人类世界会变得更好。就算你做 2C 的产品其实也会再分化，比如说今天我觉得 OpenAI 已经更像一个平台了，但是你 2C 的话你其实最终你要服务真实的这批用户究竟是谁？那今天可能有很多 AI 可能会比如说我会更偏向 Medical，更偏向 Law，但是它可能是自然形成的。

我愿意相信 Anthropic 它可能不是说今天我觉得 Coding 真的很厉害，然后我就 Bet on 它，而是因为我知道他们跟这个 Business 交流真的非常多。这个可能也是我们自己做得还不够好的一个点，虽然我们拥有巨大的优势。当然也有可能中国 SaaS 市场跟美国确实是不太一样，他们确实是非常频繁地跟客户去进行交流，那其实就很容易去发现很大的机会。今天我其实跟美国的很多 API 厂商聊起来，其实他们都没有想到 Coding 的 Token 消耗量居然会这么大。其实在中国其实还真的没有那么大的，就至少从我这边来看，但是在美国的话它就说基本上全都是 Coding。这个事情我觉得不是所有人都能 Bet 到的。今天 Anthropic 在做更多跟 Finance 相关的一些东西，我觉得也是他们自己在跟客户当中去看到这个机会。所以我觉得可能大家的分化的话可能是自然的分化，所以我更愿意去相信 AGI 该做这个事情，然后顺其自然，这个是我们该做的事情。

**主持人（广密）：**
多谢，多谢。杨强老师，您对分化这个问题怎么看？

**杨强：**
对，分化的问题，其实我更想聊一下工业界和学术界的分化。这个可能是横跨美国和中国。一直以来学术界是一个观望者，工业界在领头在往前疯跑，搞得现在很多学术界的人也在做工业界的事，像我们唐杰老师。所以这是一个好事，就好像天体物理学刚刚开始的时候，是以观测为主，伽利略的望远镜，然后才出现牛顿。所以我觉得后面一个阶段，当我们有了众多的稳定的大模型进入一个稳态的时候，我们学术界应该跟上来。

那学术界跟上来要解决什么问题呢？工业界可能还没来得及解决的一些问题，这也是我一直在考虑的问题，就是说智能上界在哪里？比方说给你一定的资源，计算资源或者能源资源，那么你能做到多好？可以更细一点，就比方说我们把这个资源怎么分配，哪些分配在训练上，哪些分配在推理上。其实我很早就做 AI，所以我 90 年代初就思考过，就做过一个小实验，就是说我们如果有一定的投入在记忆上面，那么这个记忆能够帮助推理多少？然后这个帮助会不会变成一个反向的，就是说你记得太多了，反而你记得噪音会干扰你的推理，那么有没有一个平衡点？这些问题我觉得今天还是适用的，还是一个 Fundamental 的问题。

然后我最近也在想另外一个问题，就是大家学计算机的都必定上一个计算机理论课，里面有一个重要的定理叫哥德尔的不完备定理。就是说大概的意思就是一个系统，就像我们一个大模型，它是不能自证清白的，就是说它必定是有一些幻觉是不可能消灭掉的。那可能你给更多的资源它会消灭的更多，所以这样科学问题就来了，就是说你多少资源能换取多少的比如幻觉的降低或者错误率的降低？那么这个是有一个平衡点的，这个平衡点特别像什么呢，特别像经济学，就是经济学的风险和收益的一种平衡，所以我们这也叫“没有免费午餐”定理。所以像这些东西我觉得今天就特别适合数学界、算法界和学术界和工业界一起来做研究，所以我觉得这是孕育着一个巨大的突破。

然后刚才唐杰老师也提到持续学习，我觉得持续学习特别好的一个问题是什么呢，就是它里面有一个时间的概念。就是你在持续的不断的学的过程当中，但是你会发现，比方说你把不同的 Agent 给串联起来，每一个 Agent 都不能做到百分之百的话，那么你在 N 个以后，它的那个准确率是按指数下降了。那么你怎么样能够保证它不下降？我觉得人类是用一个方法来做这个事，我们第一天有学习，第二天会在第一天的一些噪音的基础上学习，但是人类有一个方法就是睡觉，睡眠。所以我建议大家去看一本书叫《我们为什么睡觉》（Why We Sleep），是一个 MIT 的两个教授写的。那个里面就写得非常好玩，他说每天晚上睡觉其实是在清理这些噪音，使得第二天你可以把这个准确率持续的提升，就不至于是两个错误率的叠加。所以像这些理论的研究孕育着一种新的计算模式。所以我们今天可能比较关注 Transformer、Agent Computing，但是我觉得有必要去做一些探索，新的探索。这个是我回答你的问题，就是工业界和学术界要拉齐。

**主持人（广密）：**
感谢，感谢杨强老师。唐老师，因为我们从外部的感受上，智谱今天更像是走了 Anthropic 这条路线，就是 Coding 非常非常强，这个榜单上也非常靠前了。包括您刚才讲的 Long-Horizon 这种长程的 Agent，也是接下来的重点。我不知道您对分化这个主题怎么看？

**唐杰：**
我倒觉得就回到一个最本质的问题。早期的时候确实是，当时我觉得最本质还是做基座模型，智能上界这可能是最本质的。但是当时 2023 年，我记得那个时候我们是第一个做出 Chat 的，所以当时我们第一个想法，就是赶紧把 Chat 扔到网上上线了。但是当然了，后来其实结果是国家有相关的统一规定，就等到八九月份大家一起来上。但一起来上的时候，我第一个感受是十来个大模型都上来了，而且每一家其实用户都没有那么的多。当然今天分化得更严重。

后来我经过一年的思考，我觉得其实这个可能它已经不是真的解决问题。它可能甚至是在我们原来我的第一个预判，我是说它会替代搜索。到今天我相信大家很多人在开始用这个模型替代搜索，但是并没有替代谷歌，就谷歌其实反而反过来一仗，把自己的搜索革命了，就是谷歌自己做了搜索的改进。所以从这个角度上，这一仗我觉得自从 DeepSeek 出来之后，我感觉已经结束了，就没有了，这场已经结束了。

那从 DeepSeek 出来之后，应该思考的是下一个 Bet 是什么东西，就下一仗是什么东西。我觉得下一仗我是年初，我们当时团队讨论了，争论了好久，就是下一仗肯定是要让 AI 做一件事情，但做这件事情是什么，确实可以 Bet 一下。而且那个时候其实广密还到我们那儿跟我们交流，其实广密的知识特别渊博，他思考问题很深邃，就他当时的交流对我启发也非常大。后来我们团队有几个晚上，就争论了好多晚上。争论到最后，你可以叫我们运气吧，但另外一方面我们也是 Bet，就是 Bet 这个 Coding。后来我们就把所有的精力就放在了 Coding 上。

**主持人（广密）：**
对，这个就是我觉得有 Bet 是一个特别有意思的。我的一个感受就是过去一年，中国不仅是开源很强，而且大家有了自己的 Bet，而且接下来有可能分化更深，因为不只是大家都在追求通用能力，但是大家都有自己的资源禀赋，把擅长的那个点做得更好。

那接下来我觉得有一个第二个比较有意思的问题，就是因为今天这个时间点特别特殊。一个是预训练过去走了三年，大家都说可能今天走到了七八成的收益了；那个 RL 强化学习，可能今天大家也都成为共识，可能走到了比如说四五十的一个空间了，当然后面空间大家 Scale 数据、环境可能空间很大。那今天硅谷也都在讨论接下来新的一个范式，就是唐老师刚才也提到叫自主学习、自我学习。我觉得这个是一个特别值得去聊的一个话题。

要不我们先从顺雨开始。因为你从领先的 OpenAI 待过，就是对于下一个范式，这个是怎么思考的？因为 OpenAI 是一个为人类叫推进了前两个范式的一家公司，那对第三个范式从你的一个观察来讲，能给大家带来一些分享吗？

**姚顺雨：**
对，现在自主学习是一个非常热门的词，就是在硅谷大街小巷咖啡馆里面大家都在谈论。不仅形成了一个共识，我根据我的观察，可能每个人对这个东西的定义和看法都不一样。

我讲两点。我觉得第一点就是说，我觉得这个事情的 Bottleneck 其实不是方法论，而是数据或者任务。就是当我们在谈论自主学习的时候，它到底是在什么样的一个场景下，基于什么样一个奖励函数去做的？你在聊天的时候变得越来越个性化，是一种自主学习；在写代码的时候越来越熟悉每个公司独特的环境或者文档，是一种自主学习；你去探索新的科学，在这个过程中就像一个博士一样，从完全不了解有机化学是什么，到变成这个领域的专家，这也是一种自主学习。但我觉得每一种自主学习，其实挑战或者说方法论可能都不太一样。

然后我觉得第二点就是说，我不知道这是不是一个非共识，但我觉得这个事情其实已经在发生了。很明显的 ChatGPT 它是在利用这个用户数据，在不断地拟合人的聊天的风格是什么，实际上聊天的感觉越来越好，那这是不是一种自主学习？那今天 Claude Code 它已经写了 Claude Code 这个项目的 95% 的代码，从不同程度来说，它在帮助它自己变得更好，那这是不是一种自主学习？

我记得我们当时 2022 年、23 年的时候做 SWE-Agent，其实我去谷歌 AGI House 去宣传这个工作，我当时写了一个第一页 Introduction 的 Slide，就是说这个 ASI 的最重要的点就是自主学习。那今天的 AI 系统其实本质上它都有两部分，首先它有个 Neural Network（神经网络），其次它有个代码库。就是你怎么去用这个模型，是用来做推理还是用来做 Agent，它相应的有个代码库。就是说我们今天看 Claude Code 这个系统，它本质上也有两部分，一部分是比如 Opus 这个 Neural Network，另一部分是怎么样去使用这个 Neural Network 的一大堆相应的代码，无论是 Kernel GPU 的还是更往上的部署环境的，或者说它的前端或者它的 Interface 应该是什么样子。当时我想说的点就是说，其实我们做 SWE-Agent 最大的一个初衷就是说，如果有一天 Agent 能自己去 Improve Agent Repo，那它是不是就是一种 AGI？我觉得今天 Claude Code 已经在大规模的在做这个事情，但是可能人们意识不到，或者说这些自主学习的例子可能还局限在每一个特定的场景下，没有让人感觉到这个非常大的威力。但我觉得就是说这个事情已经在发生了，只是说可能它学习的效率，或者说它受它的场景的限制有各种各样的问题。那可能这个事情，我个人的看法是它可能会更像一个渐变而不像一个突变，当然这个我也很有可能是错的。

**主持人（广密）：**
我再 Follow 顺雨一个问题，就是有一些人对自主学习比较乐观，觉得 2026 年是能看到一些信号的。那从你看来，你觉得自主学习看到信号，还有哪些实际的问题要突破呢？比如说 Long Context 也好，模型的并行采样也好，或者其他。从你看来你感觉接下来还有哪些的关键条件，具备了这个信号才会发生？

**姚顺雨：**
很多人说 26 年才能看到一些信号，但我觉得 25 年其实已经有些信号了。比如说 Cursor，他们现在做的他们的 Auto-Complete Model，它其实就是每几个小时就会用最新的用户数据去不停地学习。包括他们现在新的 Composer Model，其实也是在使用这些真实环境下的数据去训练。当然大家觉得这个东西可能还没有特别石破天惊，因为他们受限于他们没有预训练的能力，他们的模型效果确实还不如 Opus，但我觉得这个很显然已经是一个信号了。

我觉得其实最大的 Bottleneck 是想象力。我们可以很容易想象，比如说强化学习或者推理这个范式，它如果实现大概是个什么样子。我们可以想象一个 O1 这样的 Blog Post，我们在数学题上面，本来是十分，现在变成了八十分，我通过强化学习有非常长的思维链去做这个事情。但比如说如果 26 年或者 27 年我们有一个范式的发生，一个 Blog Post 说我宣布了一个新的模型或者新的系统，它实现了自我学习，那我们应该用一个什么样的任务？它应该是什么样的效果？你会相信它实现的，比如说它会是一个赚钱的交易系统，它开始赚很多钱，就像 Renaissance（文艺复兴科技）的衍生？还是说它真的解决了一个人类之前没法解决的科学问题？还是别的？那我觉得可能先要想象到那个 Blog Post 是长什么样的。

**主持人（广密）：**
顺雨，因为 OpenAI 已经立了两次范式的创新了，你觉得如果 2027 年有新的范式出来，全球范围内你感觉哪一家公司继续立的范式创新的概率最大？如果说一家公司。

**姚顺雨：**
可能 OpenAI 还是会概率更大，但是我觉得因为它的商业化各种各样的变化，我觉得它的创新的基因已经被稀释了，但是我觉得它还是最有可能诞生新范式的地方。

**主持人（广密）：**
多谢顺雨。俊旸，你对下一个范式对 2027 年有什么要展开的？

**林俊旸：**
是不是 2026？那我们就聚焦在 2026 吧。如果从更实际一点来讲的话，可能刚才讲范式也还在比较早期的阶段，因为今天讲 RL 这个事情，实际上我们的 RL 的 Compute 还没有 Scale 得那么的充分，所以很多潜力其实没打出来。就是今天我们还看到很多 Infra 的问题在这里边发生，但全球范围内我觉得类似的这个问题也都还存在。

但如果要说下一代这个范式的话，我觉得一个自主学习，之前跟一个朋友聊到，就说人类不能让这个 AI 变得更厉害，就是比如说你跟这个 AI 不断的交互，你只会让它上下文变得越来越长，然后这个 AI 只会变得越来越笨，这个是一个很烦人的事情。那 Test-time Scaling 这件事情是不是真的能够发生？这个我觉得还是挺值得去思考，就是说你能拖更多的 Token，然后能让你变得更强。我至少觉得 O1 系列它一定程度上实现了这个事情。但有没有可能比如说像顺雨说的，我真的干 30 个小时是真的能够干出来很难的这个任务？我觉得今天大家去做那种 AI Scientist 这个事情，其实还挺有意义的，因为你在挑战以前很难的，甚至是做人类未曾做到的这个事情。有没有可能通过 Test-time Scaling 去进行实现？那么从这个角度上来说的话，AI 肯定是需要自主进化的，但究竟你是不是要更新参数，这个我觉得见仁见智，可能大家都有不同的技术手段去实现这个事情。

但我觉得还有第二个点是，AI 有没有可能实现更强的主动性？就说我环境可能就是我的输入的信号。比如说我现在的 AI，你必须得有人类去 Prompt 它，然后你才能够启动它。那有没有可能环境就能 Prompt 它，自己能自主思考去做一些事情？但这引发了一个新的问题就是安全的问题。我非常担心安全的这个问题是，其实不是很担心今天他讲一些不该说的话，最担心的事情是他做一些不该做的事。就比如说他今天主动的产生一些想法，往这个会场里边扔一个炸弹这种事情，我们肯定是不希望这些不安全的事情发生。但就像培养小孩一样，我们可能要给他注入一些正确的方向，但主动学习可能会是挺重要的一个范式。

**主持人（广密）：**
是的，俊旸又提了一个主动性。主动性其实也可能是 26 年非常关键的一个 Bet。我在 Follow 俊旸一个问题，就是如果自主学习 26 年看到信号，你感觉可能是在哪些任务上做什么样的任务，会先看到是模型训练模型了，最强的模型可以提升自己了，还是说自动化的 AI 研究员了？你有期待在哪些地方先看到吗？

**林俊旸：**
我觉得自动化的 AI 研究员可能甚至都不是那么需要自主学习，我觉得可能很快 AI 训 AI 这件事情就可以实现。我看着我们的同学每天在干的这个事情，我都觉得造得很快就能把他们替代掉。但是我觉得可能是更持续的理解用户这件事情，比如说 Personalization（个性化）这件事情其实还挺重要的。就比如说过往我们在做推荐系统的时候，其实用户这个信息它是持续的输入是会让你整个系统变得更强，虽然它的算法其实是很简单。但今天在 AI 这个时代，它是不是能够更懂你？就是你的这些信息的输入是你成为最好，我们过去讲那个 Copilot，但其实今天连 Copilot 都没有实现，就是能不能真的成为我的 Copilot 这个问题。所以我觉得如果说自主学习的话，可能会是在跟人的交互上，比如说 Personalization 这件事情上可能就能做到。但是以什么指标来进行衡量，我觉得稍微有点不太好说。因为在推荐的时代的话，Personalization 你做的这个越好的话，那么别人可能就点的越多买的越多。但是在 AI 这个时代覆盖到人类的生活方方面面的时候，真正的 Personalization 的衡量指标是什么，我们其实不太知道。所以今天我感觉可能更大的从技术上的挑战是说，我们今天的 Evaluation 不知道该怎么做，这个可能是我们更值得研究的问题。

**主持人（广密）：**
明白。对，因为你说到了主动，包括个性化。你感觉如果实现记忆这个点，这个 26 年能看到技术的突破性的跨越吗？

**林俊旸：**
我个人观点是大量的技术，其实所谓的突破性的话都是一些观测问题，它其实都是在线性的发展，只是人类对它的感受非常的强烈。也包括像 ChatGPT 的出现，其实对于我们做大模型的来说，其实就是在线性的增长。那现在的话大家就是在做 Memory 这个事情，你说这个技术方案对还是不对呢？我觉得很多方案也没有什么对错之分，但是做出来这个效果，至少我拿我们自己这个献个丑，就是我们自己的 Memory 呢，它看起来好像知道我过去干了什么，但只是记起来过去的这个事情，每次都会叫一遍我的名字，但其实并不显得你很聪明。但你的 Memory 有没有可能到某一个临界点的时候，让人觉得说，你结合你的 Memory 真的能够——就像生活当中的人一样，过去大家讲这个电影叫《Her》——《Her》的话其实它就真的很像这个人，就理解你的 Memory。可能就是在那一下人类的感受就觉得突然间迸发，那可能就是那一种。那我觉得多少少也需要一年时间，很多时候其实我觉得技术也没有发展这么快，只是大家比较卷，觉得每天都有这个新的东西，但其实技术就是在线性的发展。只是我们可能是在观测的角度，在处于一个指数上升的这个阶段。比如说 Coding 能力的一点点提升，可能就能带来很多的生产价值，大家可能就觉得 AI 发展很快。但从技术的进展上来说，可能我们就多干一点点这个事情。因为每天看我们自己做的事情都还真的挺土的，就解的那些 Bug 就真的都不好意思拿出来跟大家讲，就非常的丑陋。那如果这样做我们都已经能够做到这样的成绩的话，那我觉得可能未来算法的 Infra 结合得更好的话，可能能更加大有可为。

**主持人（广密）：**
多谢，多谢俊旸。那个，杨强老师？

**杨强：**
对，我一直以来是做这个联邦学习。联邦学习的主要思想就是说多个中心大家协作。那么我现在越来越多的看到很多，就是有本地资源不足，但是本地的数据有很多的隐私和安全的要求。所以这样我们就可以想象，就是现在大模型的能力越来越强，那这种通用性大模型和本地的这种特殊性的小模型，或者是领域专家的模型，如何协作？我觉得这种协作变得越来越可能。像美国我看到 Zoom，就是黄学东他们做的叫 Federated AI 系统，就是他做了一个很大的一个基座，这个基座大家都可以插进来，然后他就可以在一个 Decentralized（去中心化）状态下，能够既保护隐私，又能够和通用大模型有效的沟通协作。我觉得这种开源模式特别好，一个是知识的开源，一个是 Code 的开源模型阶段。所以我觉得尤其在像医疗、金融这样的场景下，会越来越多看到这样的现象发生。

**主持人（广密）：**
多谢杨强老师，联邦学习。对，唐老师？

**唐杰：**
我其实对今年会有比较大的范式革新，我倒是挺 Positive 的。我觉得我倒不说太细，因为那几个点，就像我刚才讲的，包括持续学习，还有 Memory，甚至模型架构，甚至多模态，我觉得都有可能出现新的范式的变革。

但我觉得一个大的趋势，我来说一下为什么会产生这样的一个范式。我觉得原来其实是工业界跑得远远快于学术界。我记得在去年和前年的时候，回到清华跟好多老师聊天的时候说，能不能做大模型？很多老师是第一没卡，不是没卡，是卡的数量几乎为零。那么工业界是有一万片，学校是零片或者一片，那个倍数是一万次。但是到现在的时候，很多学校已经有很多卡了，而且很多老师已经开始做了很多大模型，包括硅谷那边有很多老师都开始做这种，甚至模型架构、持续学习这些相关的研究。所以它已经不是一个——原来我们都总觉得工业界在 Dominate 这些——其实今天我觉得在 2025 年底到 2026 年初的时候，我觉得这一现象不大存在了。可能还有十倍的差，这里一万片，那里一千片，但是它已经孵化出种子了，我觉得在学术界它有创新的基因，有这个可能性了，这是我觉得是第一个。

第二个，我觉得一个创新的出现，它一定是某个事情，它有大量的投入，并且它的 Efficiency（效率）变成瓶颈了。那么现在在整个大模型里面投入已经巨大，但是那个 Efficiency 并不高。也就是我们继续 Scaling，你说有没有收益？肯定是有收益的。比如说原来我们 Data，你比如从 2025 年初，当时可能十个 TB 的数据，现在三十个 T，甚至我们可以 Scaling 到一百个 T。但一百个 T 你 Scaling 上去以后，你的收益有多少？还有你的计算 Cost 有多少？你就变成这么一个问题。你不创新，这个就变成一个你可能花掉了十个亿，花掉了二十个亿，但是你的收益很小，就不值得了。

那另外一方面，对于新的这种智能上界，假如我们每一次我们都要重训一个基座，再重训很多 RL。像 24 年初那 RL 的时候，大家很多人会觉得我接着训，它就收益比较的有。但到今天的时候，你再记得疯狂的叫 RL，收益也是有的，但就没有那么 Significant，还是一个收益效率的问题。就可能我们未来，也许可以定一个——一方面我们继续要 Scaling Up，我刚才其实讲的，我说那是反正最笨的办法就是 Scaling，因为 Scaling 我们肯定有收益，所以这是一个典型的工程做法，Scaling 肯定会带来智能的上界的提升，毫无疑问，你只要 Get more data——但是第二个方法，我觉得应该定一个叫 Intelligence Efficiency，就是说智能的效率，我们获得智能的效率。就是我们用多少的投入，能获得智能的增量。如果我们能用更少的获得它增量，而且我们现在已经变成一个瓶颈了，假如能用更少的一个范式，获得同样智能提升，这个它就变成一个瓶颈式的事情。所以我是觉得 2026 年，一定有这么一个范式的发生。当然我们也是在 Bet，我们也在努力，我们希望这个发生在我们身上，但也不一定。

**主持人（广密）：**
对，我跟唐老师也是一样，非常乐观的。因为其实每个领先的模型公司，每年它的计算量，实际上是每年 Compound 有十倍左右。其实大家手上的计算资源多了，而且人才也涌入的越来越多，其实大家手上卡片多，做的实验多了，其实它就是一个实验工程，有可能某个点就出来了。

对，刚才唐老师也聊到一个，怎么衡量智能水平的这个点。我觉得第三个就是，我们可以一起聊一下 Agent 这个战略。因为最近我跟很多研究员聊，大家都提到，对 26 年还有一个很大的预期，说 Agent 今天可以在后台，比如说推理三到五个小时，做人类比如说一到两天的工作量。大家期待说 26 年可以做人类正常工作个一周到两周的工作量。那这也是一个非常大的一个变化，因为它不再只是一个工具，那个就是唐老师提的说只是一个 Chat，而是说真的在自动化你一整天，甚至一周的这个任务流。那这样的话其实 26 年有可能是 Agent 真的就要创造经济价值的关键的一年。所以 Agent 这个问题，我们可以让大家展开聊一下。因为大家也是顺雨刚才提的垂直整合，既有模型又有 Agent 的产品，包括我们看到硅谷的几个公司，也都从模型到 Agent 也是端到端都做了。因为顺雨你花了很多时间做 Agent 的研究，你对 26 年这个 Agent，比如说 Long Horizon 的这种 Agent，这个真的能 Automate 人类比如说一周到两周的工作，对 Agent 的战略，包括从模型公司的出发点，会怎么思考这个问题？

**姚顺雨：**
我觉得还是像刚刚说的，我觉得在 2C 和 2B 可能不太一样。目前看起来的话，我觉得 2B 的情况就是现在它已经达到了一个不断上升的曲线，目前看起来好像没有要变慢的趋势。我觉得 Anthropic 这家公司很有意思一点，它基本上不做什么创新，它就是觉得你模型预训练变大，然后老老实实地把 RL 这些东西做好。然后你只要预训练不断地变大，所以我觉得它就是会越来越聪明，它就会带来越来越多价值。然后 Anthropic 这个公司很有意思一点，从某种程度来说，做 2B 其实你的所有的目标之间是更一致的。你的模型的智能越高，然后你解决的任务就越多，你解决的任务越多，在 2B 下你带来的收入就越大，那所有事情就 Aligned 了。那做 2C 的一个问题就是说，我们都知道 DAU 或者说这些产品的指标，其实是和模型的智能很多时候是不相关的，或者说甚至有相反的关系。那我觉得这是 Anthropic 能够聚焦的另一个很重要的原因，就是说它只要真的把模型越做越好，那它的收入就越来越高，所有事情全部都是非常非常 Aligned。

目前看起来我觉得 2B 才，我觉得就是或者说生产力的这种 Agent 才刚刚开始。很多时候我觉得现在可能除了模型之外有两个 Bottleneck，一个是环境问题或者说 Deployment 问题。我觉得就是说，我之前在 OpenAI 之前我在一个叫 Sierra 的公司实习过，这是一个 2B 的客服公司。我觉得在 2B 公司工作过还是有很多收获，我觉得最大的收获就是说，我感觉即使今天模型不再变好，就是所有的模型训练全部停止了，但是我们就是把这些模型去布置到这个世界上各种各样的公司，那它可能已经能带来今天比如 10 倍或者 100 倍的收益，或者说可能已经对 GDP 产生一个 5% 到 10% 的影响。当然今天我觉得它对 GDP 的影响远远不到 1%。

我觉得第二点就是说可能教育非常重要。我观察就是说现在人和人的差距在拉大，就是因为更多时候不是说 AI 替代了人的工作，而是说会使用这些工具的人在替代那些不会使用那些工具的人。就像当年电脑刚刚出来，你如果去转身去学会学习编程，Versus 你还在使用计算尺，在使用算盘，那这就差距巨大了。我觉得可能今天中国能做的一个最大的有意义的事情，其实就是更好的教育，教育大家怎么更好地去使用像 Claude Code 或者 ChatGPT 这样的产品。当然 Claude Code 可能在中国用不了，但是我们可以用 Kimi 或者智谱这样国产的模型。

**主持人（广密）：**
多谢多谢顺雨。俊旸，你怎么看接下来千问未来的一个生态位或者分化的一个 Bet？因为千问也有一个生态，就是说千问自己做 Agent 以及扶持生态的通用 Agent，你也可以展开讲讲。

**林俊旸：**
这里可能涉及一个产品哲学的问题。当然 Manus 确实很成功，但是套壳是不是个未来这本身也是个话题。我觉得今天到这个 Timing，我其实比较同意你的观点，叫“模型即产品”。我跟 TML 的人聊他们那个叫 Researcher's Product，其实我挺喜欢这个事情。包括我的视角看 OpenAI，我觉得还挺多这种事情，就挺多 Researcher 自己能够成为产品经理，End-to-End 把这个东西给做起来。包括今天我们自己内部的 Researcher，都想做更多面向真实世界的一些东西。

我其实愿意相信说接下来的 Agent 的话，是可以做到刚才所说的这个事情，而且跟刚才所提的 Self-evolvement 以及主动学习，其实都有比较强烈的关系。比如说他能干这么长这个时间，他其实自己就得在这个过程中进化，并且他要决定去干什么东西，因为他收到的指令是一个非常 General 的任务。所以我们现在 Agent 已经开始越来越变的是那种托管式的 Agent，而不是说我要不断跟你来来回回交互的那种形式。从这个角度上来说，他对模型的要求其实是很高的，就是说模型就是这个 Agent 本身，Agent 就是这个产品本身。如果他们都是这个一体化的话，那么今天也许做基础模型本身也其实也就是在做这个产品。那从这个角度上来说的话，我觉得如果不断提升模型能力的上限，包括 Test-time Scaling 做上去的话，他确实能够做到这个事情。

但我觉得还有一个点是跟环境交互有关系，就我们现在交互的这个环境还不是很复杂，就这些都还是电脑的这个环境。我有朋友是做跟 AI for Science 比较相关的，那 AI for Science 比如说今天你干 AlphaFold 这个事情，其实你最后干出来它还没有到内部，就距离比如说举个例子，比如说制药这件事情，其实你就算今天用今天的 AI，可能不一定能帮到你那么多，因为你要去做湿实验，要去做这些事情才能得到反馈。有没有可能我们未来的 AI 能够环境复杂到，可能是真实的人类世界环境，就指挥这个机器人就去做湿实验，去加快这个效率？否则的话比如按照现在这个人类的效率，现在体质非常低的，我们甚至还要雇佣很多外包，来去在这个实验环境里面去做实验。如果能达到这一个点的话，可能才是我想象当中说人类要做很长时间活，而不是说仅仅是在电脑当中比如说写个文件这些东西。这些东西我觉得可能今年很快就可以完成，但我觉得接下来三年到五年的时间，可能这个事情可能会更加有意思一些，那这个的话可能又要跟具身智能结合在一起了。

**主持人（广密）：**
我想 Follow 俊旸一个尖锐点的问题，从你的角度看来通用的 Agent 这个机会是创业者的吗？还是说模型公司是一个时间问题，总会把通用 Agent 做好的？

**林俊旸：**
我不能因为我做基础模型，我就去做创业导师，我做不了这个事情。那我只能借成功人士的那句话，这个 PG（Paul Graham）他说，他说他做通用 Agent 最有意思的事情就是，长尾反而是更值得关注的这个事情。或者是说今天 AI 更大的魅力是在长尾，就是说你如果是马太效应，你这个头部的这个东西其实挺容易解决的。当年做推荐的时候，其实我们就看到那个推荐其实非常集中的商品都是在头部，但我们其实是想把尾部这个东西推过去，但是我当时做就非常的遭殃，我作为一个干 NLP 和多模态的人，碰到这个推荐系统，然后我去干这个解马太效应，基本上是奔着死路去的。但我觉得今天的所谓的 AGI 其实就在解这个问题，就是说你做通用 Agent 是能不能把这个长尾的问题给解决。就是说今天我一个用户，我真的寻遍各处我都找不到能够帮我解这个问题的，但就在那一刻我感受到了 AI 的能力，就是全世界任何一个角落我寻遍各处都找不到，但是你却能帮我解决，可能这就是 AI 最大的魅力。所以你说要不要去做这个通用 Agent 呢？我觉得见仁见智。如果你是一个套壳高手，你套的可以比这个模型公司做的更好，我觉得可以去做。但如果你没有这个信心的话，这个事情可能是留给模型公司做这个模型即产品的时候，因为他们遇到问题的时候，其实我只要训训模型，我只要稍稍看，我可能这个问题就解决了，所以见仁见智。

**主持人（广密）：**
其实解决长尾的问题，模型公司就是说算力加数据，好像你解决下来也挺快的。

**林俊旸：**
今天 RL 最有意思的地方，我觉得是我们发现修问题比以前容易。以前修问题很难，我举一个 B 端客户的情况，他们说我们自己要做 SFT，你能不能告诉我这个通用数据怎么配比？每次我们都很头痛，因为我们觉得对方不太会做 SFT，他那个数据就非常的垃圾，他可能觉得他非常的有用。今天有了 RL 之后，你可能真的很小的一个数据点，甚至你都不需要这个标注，你只要有这个 Query，有这个 Reward，这个东西稍微训训，然后合并起来其实也非常的容易，可能是今天技术的魅力。

**主持人（广密）：**
多谢俊旸。那个，杨强老师？

**杨强：**
对，我觉得 Agent 出现应该有四个阶段。我们看一个是目标的定义，是由人为定义的还是自动定义的；第二个是说规划，就是中间的 Action，规划也可以由人来定义，也可以由 AI 自动定义。所以这样就自然分为四个阶段了。我觉得我们现在在一个非常初级的阶段，就是目标也是人定义的，然后规划也是由人来做的。所以现在的这些 Agent 的 Definition 的软件系统，基本上是一个更高级的、一个 Very High Level Programming Language。但是我预料未来会出现一个大模型观察人的工作，然后把人的尤其是这种 Process Data 给使用起来，最后目标也可以是大模型来定义，然后规划也可以是由大模型来定义。所以 Agent 应该是由大模型内生的一个 Native 的系统。

**主持人（广密）：**
多谢，多谢杨强老师。唐老师？

**唐杰：**
我觉得那个 Agent 确实它有几个决定了 Agent 未来的走势。我觉得第一个就是说这个 Agent 它本身有没有解决人类的一个事情，而这个事情它是不是有价值的，而价值有多大。如果你说比如说原来 Agent 像 GPTs 出来也是做了很多很多 Agent，在那个时候其实你会发现那个 Agent 都很简单，都非常简单，最后发现 Prompt 就解决了，那这个时候那些大部分 Agent 慢慢就死掉了。所以我觉得第一个是解决这个 Agent 这个事情它有多有价值，然后以及真的能不能帮到人，这是第一个。

第二个就是说白了是做这个事情咱们 Cost 有多大。就是如果 Cost 特别大，那这个时候其实也是一个问题。那刚才其实俊旸也说的，那也许我调用一个 API 就能把这个问题解决了。但是反过来假如调个 API 就能解决，那么这个 API 它本身有可能它觉得当这件事情价值很大的时候，它就会把它做进去，它就会把它做进去，这是个矛盾，这是个非常矛盾的事，就基座和应用永远是个矛盾。

最后一个维度就是做应用的速度。就是你如果说我有个时间窗，我能够拉开半年的时间窗，我迅速的把这个应用满足了，半年以后要么迭代要么怎么着，反正总之你能往前走。我觉得这也是一个，说白了大模型时代到现在，更多的是在拼速度拼时间。也许一个决策正确，就像你刚才说也许我们 Bet 代码正确了，那也许我们就会在这个方面走得更远一点，但是也许 Bet 失败了以后就半年就没了。所以今年我们只是在 Coding 在 Agent 这块，我们 Bet 了一点点，所以我们还现在我们 Coding 啊、调用量这些都还不错。所以我觉得也更多的也是一个 Bet 吧，做 Agent 可能未来也是一个 Bet。

**主持人（广密）：**
多谢多谢。因为过去模型公司既要追通用能力，可能它在优先级上就没有花那么多精力去探索。其实那个通用能力追上来之后呢，其实我们也更多的期待 26 年这个智谱、千问有更多自己的 Claude Code 时刻和 Manus 时刻，我觉得这个是非常值得去预期的吧。

因为第四个问题也是最后一个问题，我觉得比较有意思，就是因为这个活动包括这个时间点，我觉得是更多值得去展望真的未来。就是我其实挺想问大家一个问题，就是在三年和五年以后，全球最领先的 AI 公司是一个中国团队的概率有多大？然后我们从今天的一个跟随者变成一个未来的引领者，这个文化包括关键条件，到底是还有哪些需要去做好的？就是未来三到五年，我在想这个概率有多大以及需要哪些关键条件。

因为顺雨，因为你是经历过硅谷跟中国两个体感的，你对这个概率的判断和需要哪些关键条件的判断是怎么样的？

**姚顺雨：**
对，这个我觉得概率还挺高的，我还是挺乐观的。因为目前看起来就是说，任何一个事情它既然——就它一旦被发现出来——在中国都会很快地做的，就是能够去 Catch Up 或者说能够去复现，然后能够去在很多局部去做得更好。我觉得这个事情，就包括之前制造业、电动车这样的例子已经不断地发生。

我觉得可能几个比较关键的点，一个可能是中国的光刻机到底能不能突破。如果最终算力变成了 Bottleneck，我们能不能解决这个算力问题。算力目前看起来就是说，我们有很好的电力优势，我们有很好的基础设施的优势，可能主要的瓶颈一个就是产能，包括光刻机以及这个软件生态。但如果这个问题解决，那我觉得会是个很大的帮助。

我觉得可能另一个问题就是，除了 2C 之外，能不能有个更成熟或者更好的 2B 的市场，或者说可能有没有机会在国际的商业环境去竞争。因为今天我们看到很多做生产力或者做 2B 的这些模型或者应用，它还是会诞生在美国，因为那些付费意愿更强，那些 2B 的文化更好。在中国今天，在中国内做这个事情很难，所以大家都会选择出海或者做国际化的事情。我觉得这两个可能是比较大的客观上的约束。

我觉得可能还有个更重要的是主观上的这个概念。就是说，我最近因为也在跟很多人聊天，我之前的感受就是说，在中国其实有非常非常多非常强的人才，然后任何一个事情只要它被证明地做出来，很多人都会去非常积极地去尝试，并且想要甚至做得更好。但我觉得今天中国还是——就这种想要破新的范式，或者做这种非常冒险事情的人——可能还是不够多。当然就这里面可能有经济环境、商业环境，包括文化的因素。但是我觉得可能如果分家一点的话，就是主观上能不能有没有更多就是有这种创业精神或者冒险精神的人，真的想要去做这种前沿探索，或者新的范式突破的事情。因为目前来看，一个范式一旦没发生，那我们可以用很少的卡，很高的效率去 Catch Up，或者说甚至局部做得更好。但是我们到底能不能去引领新的范式，我觉得这可能是今天中国唯一要解决的问题。因为其他所有事情，无论是商业还是产品设计，还是这种 Catch Up 做工程，我们都已经比美国做得更好。

**主持人（广密）：**
我在 Follow 顺雨一个问题，你对中国的 Lab 里面的研究文化，有什么要呼吁的吗？因为其实你感受过 OpenAI 也好，或者说这个湾区的 DeepMind 这种研究文化。就中国的这个研究文化跟美国的这个研究文化，有什么差异的地方？就是你感觉包括这个研究文化，对作为一个 AI Native 的公司，有哪些根本性的影响？你对这个有呼吁或者建议的吗？

**姚顺雨：**
对，我觉得每一个地方的研究文化都很不一样，可能比如美国不同实验室之间的区别，可能比中美之间的区别还要大，在中国也一样。

我个人觉得可能有两点吧。一点就是说，我觉得在中国大家还是更喜欢做更安全的事情。比如说今天预训练这个事情已经被证明可以做出来了，那这个事情其实也非常难做，有很多技术问题要解决，但是只要这事情一旦被证明能做出来，那我觉得我们都很有信心，就是说几个月或者一段时间内就把这东西搞清楚，然后去决定。但是如果今天要让一个人说，我跟你说要探索一个比如长期记忆或者说持续学习，然后这个事情大家也不知道怎么做，能不能做起来，那这个的话我觉得还是比较困难。但当然的话我觉得可能也不只是说，大家更喜欢做确定性的事情，不太愿意做这种创新的事情。我觉得也有很重要一点，就是说文化的积淀以及整体的认知，其实是一个需要时间沉淀的事情。我觉得，对，就是可能真的就是说，在 OpenAI 比如说做 RL 这个事情，它可能是 22 年就开始做了，那国内可能是 24 年就开始做，那对这个东西的理解可能会有一些差异。或者说中国的 RL 没有 Scale Up 这么大，那我觉得可能很多也是时间问题的。就是说当你积淀的文化或者底蕴更深，从某种潜移默化的程度可能会影响人的做事方式，但是它很微妙，我觉得很难通过这些榜单这些东西去体现。

当然就是说到榜单，我觉得第二点我想要留意的观察，就是说我觉得中国大家还是对于刷榜，或者说这些数字会看得更重一些。我觉得这一点上我觉得可能像 Anthropic，我觉得可能就会做得比较好。就是包括我觉得可能 DeepSeek 做得也比较好的一点，就是说他们可能没有那么关注这个榜单的数字，可能会更注重就是说第一什么是正确的事情，第二是什么是你自己体验能体验出来好还是不好。我觉得这个还是挺有意思的，就是说因为你看 Claude 的模型，可能在很多编程或者软件工程的榜单上可能也不是最高，但是大家都知道这个东西是最好用的。我觉得这个还是需要大家能够去走出这些榜单的束缚，能够去坚持自己觉得什么是正确的或者什么是好。

**主持人（广密）：**
多谢多谢顺雨。俊旸，概率和条件。

**林俊旸：**
你这个问题本身是一个危险的问题。理论上这个场合是可以泼冷水的，但是如果从概率上来说的话，我可能想说一下中国和我感受到的美国的差异。比如说美国的 Compute，可能整体比我们大概一到两个数量级。但是我看到不管是 OpenAI 还是 Anthropic，他们大量的 Compute 投入到下一代的 Research 当中去。我们今天相对来说捉襟见肘，光交付的话可能就已经占据了我们绝大部分的 Compute，这个会是一个比较大的差异在这里边。这可能是一个历史以来就有的问题，创新是发生在有钱的人手里还是穷人的手里？穷人不是没有机会，因为我们觉得这些富哥真的很浪费卡，他们在训这么多东西，可能训了很多也没什么用。但今天穷的话，你其实会想，比如说你今天所谓的算法、Infra 联合优化这个事情，其实如果你真的很富的话，你真的没有什么动力去做这个事情。我觉得可能更进一步的，刚才顺雨也提到光刻机的这一个问题，未来有可能还有一个点是，如果从软硬结合的角度，是不是真的有可能 End-to-End 的做出来？比如说我们下一代的模型结构和芯片，其实都有可能是一起把它给做出来的。

我特别记得我在 2021 年的时候，当时我们在做大模型，因为阿里做芯片，然后就来找我说，能不能预测一下三年之后，这个模型是不是 Transformer？三年之后这模型是不是多模态？为什么是三年呢，他说我们需要三年的时间才能流片。我当时给大家回答是，三年之后在不在阿里巴巴我都不知道，但最后我今天还在阿里巴巴，然后它果然还是 Transformer，它还是多模态。我就非常地懊悔，为什么当时没有去催它去做。但当时我们这个交流其实非常鸡同鸭讲，他给我讲了一大堆东西我完全听不懂，然后我给他讲他也不知道我们在做什么，就错过了这个机会。但这个机会有没有可能再来一次？我们虽然是一群穷人，但是是不是有可能穷则生变？那我觉得比如说创新的机会可能是发生在这里。

但我觉得可能我们需要改变的是，比如说我觉得今天我们的教育在变好。因为我感受比如说我属于 90 年代靠前一些，顺雨都属于 90 年代靠后一些，我们团队里面好多 00 后，我就感觉大家这个冒险精神变得越来越强。当然美国人他天然有非常强烈的冒险精神，一个很典型的例子就是当时这个电动车刚出来的时候，甚至这个天篷会漏水的情况下，甚至可能你开车它可能会意外身亡的情况下，一样有很多富豪们他都愿意去做这个事情。但在中国我相信富豪们是不会去干这个事情，大家会做一些很安全的事情。但今天大家的冒险精神开始变得更好，中国的比如说营商环境也在变得更好的情况下，我觉得是有可能带来一些创新的。概率没那么大，但真的有可能。

**主持人（广密）：**
如果拍一个数字呢？你说百分之多少？

**林俊旸：**
对，三年到五年后，最领先的那个公司是一家中国公司的概率。我觉得百分之二十吧，我觉得百分之二十已经非常的乐观了，因为这里真的有很多历史积淀的原因在这里。

**主持人（广密）：**
我再 Follow 一个问题，就是你内心的比如说中国的模型跟美国的模型，这个差距，它这个 Dynamic 变化，有的地方在追上来，有的地方他们的算力又在拉大，你内心这个 Gap 变大的恐惧感强吗？

**林俊旸：**
今天你干这一行就不能恐惧，必须得有非常 Chill 的心态。从我们心态上来说就是能干这一行已经非常不错了，就是能够做大模型这件事情已经非常的幸运了。那就是说我觉得还是看你的初心是什么，因为其实刚才顺雨提到一个点说，你的模型可能不一定那么强，在 C 端的里边其实是 OK 的。我可能转换成另外一个角度去思考这个问题是，我们的模型为人类社会带来什么样的价值。只要我去相信我这个东西能够为人类社会带来充分的价值，能够帮助人类的话，它就算不是最强的我也愿意接受。

**主持人（广密）：**
多谢俊旸。杨强老师，因为您经历过很多 AI 的周期，也看过很多中国 AI 的公司变成世界最强吗？您对这个问题的判断。

**杨强：**
我们可以回顾一下互联网的发展，一开始也是从美国开始，但是中国很快就赶上了，而且应用像微信就是世界第一的。所以我想 AI 的话是一个技术，它是一个 Enabling 的技术，它并不是一个终端的产品。但是我们中国有很多的聪明才智，会把这个产品发挥到极致，不管是 2B 还是 2C。但是我可能更看好 2C，因为百花齐放，中国人群策群力。但是 2B 可能有一些具体的限制，像付费意愿、企业文化等等，这些可能也在改变。

但是我最近也特别的观察一些商业，方便跟商学院的一些同学探讨。比方说美国有一个公司叫 Palantir，它的一个理念就是说，不管 AI 现在发展到什么阶段，我总是能在 AI 里面发现一些好的东西，应用在企业上。那么中间肯定是有 Gap，我们要给它拟合，它有一个办法叫本体，它用一个本体的方法。其实我观察了一下，大概的思想就是我们以前做的迁移学习，就是说把一个 General Solution 能够用到一个具体的实践当中，用一个本体来做一个知识的迁移，这个方法非常的巧妙。当然它是通过一种工程的方法，叫前端工程师 FDE 来解决的。不管怎么样，我觉得像这种就非常值得我们学习。我觉得中国的企业像 AI Native 的公司，应该发展出这样的一些 To B 的 Solution 来，我相信会的。所以我觉得 To C 肯定是百花齐放的，To B 可能也会很快的跟上来。

**主持人（广密）：**
多谢杨老师。唐老师？

**唐杰：**
首先我觉得确实也要承认，在中美，我觉得无论从研究，尤其是企业界的 AI Lab，我觉得和美国是有差距的，这是第一个。但我觉得也是在未来中国，其实现在慢慢变得越来越好，尤其是 90 后、00 后这一代起来，我觉得慢慢变得真的是远远好过之前。

我有一次在有一次 Workshop 的一个会上，我说过一句话，我说我们这一代是最不幸的。他说为什么呢？我说我们这一代，其实你看我们上一代还在，我们现在还上一代也在继续工作，我们也在工作，所以我们还没有出头之日。然后很不幸的下一代已经出来了，现在世界已经交给下一代了，已经把我们这一代无缝的给跳过了。那其实开玩笑的。

但我觉得最有意思的是什么呢？我觉得可能未来中国也许的机会吧，第一个就是一群聪明人真的敢做特别冒险的事，我觉得现在是有的，现在是有的。00 后这一代包括 90 后这一代是有，包括俊旸、Kimi、还有顺雨这些都是愿意，而且非常敢愿意冒风险来做这样的大冒险的事。

我觉得第二个倒是确实是咱们的，可能这个环境要更好一些，无论从国家的环境，就是我的意思是说，比如说大企业和小企业之间的竞争，那创业企业之间的一些问题，还有包括我们的营商环境。比如说像刚才俊旸说的我还在做交付，其实这些都我觉得把这个环境如果比较的更好，让大家一群聪明人，又敢于冒险的聪明人，有更多的时间去做这样创新的事情。比如说让俊旸这样的去做，有更多时间来做创新的事情，我觉得这是第二个，也许是我们政府包括我们国家可以来帮忙改善的一个事情。

第三个我倒觉得是回到我们每一个人自己身上了，就是我们能不能坚持。就是我们能不能愿意在一条路上，我们敢做，我们敢冒险，而且环境也还不错，是吧。我觉得环境肯定不会是最好的，永远不要想环境是最好的。我觉得我们恰恰可能也是幸运，我们在经历一个环境从也许原来可能没那么好，慢慢变得更好的一个时代，我们是经历者，也许就是财富。包括经历收获最多的人，如果我们笨笨的坚持也许走到最后的就是我们。感谢大家。

**主持人（广密）：**
感谢，感谢唐老师。所以我们也很想呼吁说，应该更多的资源资金投入到中国的 AGI 行业，有更多的算力，然后让更多的 AI 的年轻的研究员搓卡，就是有可能搓个三五年，中国也有三五个自己的 Ilya，这是我们未来三五年很期待的。感谢大家。

非常感谢，好，感谢大家。接下来邀请张院士来对今天有一个压轴的点评。