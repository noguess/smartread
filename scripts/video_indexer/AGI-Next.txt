Title: 清华 AGI-Next 圆桌对话：唐杰，杨强，林俊旸和姚顺雨都说了什么干货？｜华尔街现场
Video ID: Y4jRSIIdmB8
============================================================

Hello Hello 我是接下来拍拢的主持人广觅。 刚才我在台下听有几个感受吧。 第一就是唐老师的号召力很强, 清华的人才非常好, 不仅是国内包括海外, 清华人的比例非常高的。 感觉这一波好像跟隔壁学校在AI这一波拉开差距了。 第二就是我刚才听几个talk的感受, 不止Follow,不止开源, 而且都在探索自己的下个范式。 而且不只是Coding, 都在探索自己的产品形态。 这个时间点特别有意思, 就是说, 2025年其实是中国开源模型大放异彩的一年, 四家开源四节在全球取得了非常大放异彩的一年。 而且是Coding过去一年有10到20倍增长的一年, 包括海外也在提Scaling到底走到哪一步了, 就是有没有新的范式出来了。 所以今天这个活动接下来这个panel, 我觉得要讨论接下来怎么走是特别有意思的。 接下来我们邀请几位嘉宾, 杨强教授,唐杰老师,俊阳和顺宇。 我们先从第一个比较有意思的话题聊起来, 硅谷的其实几家也都在明显的做分化, 我觉得从分化这个主题可以先聊起来。 Anzor Peak其实是对中国模型公司有一个非常大的启发的, 就是硅谷的竞争那么激烈, 它没有完全Follow全都做, 而且是专注到了企业,专注到了Coding,专注到Agentic。 所以我也在想, 接下来中国的模型会分化成自己想要的哪些方向, 我觉得分化这个主题是一个蛮有意思的。 那个我看顺宇也上线了, 那个要不顺宇可以开场给大家讲一讲, 包括你最近在忙什么。 大家好, 我现在是不是一个巨大的脸在会场, 不好意思,今天没法亲自来北京, 但是很高兴参加这个活动, 最近就忙着做模型做产品, 我觉得就是做AI一个很正常的高台。 回国感觉还是挺好的,吃的好吃的好很多。 顺宇,你能展开聊聊你对模型分化这个主题的想法吗? 就是说硅谷你看也都在分化, 比如说Anthropy做了Coding, 中国的模型做了开源, 过去Coding提得也很快, 包括Google Gemini也没有全都做, 它先把全模态这个点做得很好, 你的老东西在重点做2C, 我不知道,因为你是横跨中美的, 这个体感就是可以给大家讲讲你的这个体感, 接下来不管说自己也好, 哥家也好,分化这个点你是怎么思考的? 对,我觉得有两个大的感受, 一个感受是2C和2B明显发生了分化, 我觉得另一个感受就是说垂直整合这条路, 以及就是模型和应用分层这条路, 也开始出现了分化。 我先说第一点, 我觉得很明显的就是说, 当大家想到AI的SuperApp, 现在大家想到就是两个对吧, 一个是ChatGBT, 然后另一个是Cloud Code, 然后大家可以认为分别是做2C和2B的典范, 但是我觉得很有意思一点就是说, 我们今天用ChatGBT的时候, 其实和去年应用, 对于大部分人大部分时候, 其实感受的变化已经没有那么强烈了, 但是相反,Cloud Code, 可能一年前, 就Coding的这个革命还没有开始, 但是这一年就是已经夸张一点说, 已经在重塑整个计算机行业做事的方式, 就是人已经不再写代码, 而是去用英语和电脑去交流。 我觉得很合适的一点就是说, 对于2C来说, 大部分人大部分时候, 其实不需要用到这么强的智能, 就是说可能今天用ChatGBT和去年相比, 写抽象代数或者去做加洛华理论的能力变强, 但是大部分人大部分时候感受不到, 大部分人其实可能还是在, 尤其在中国, 对吧, 更多像是一个搜索引擎的加强版, 然后很多时候你也不知道该怎么样去用, 去把他的这个智商给激发出来, 但是对于2B来说, 我觉得很明显的一点就是说, 智能越高很多时候就代表生产力越高, 就代表你可以赚的钱越多, 就是这些东西都相关联。 那对于2B来说, 还有一个很明显的点就是说, 大部分时候其实很多人他就愿意用最强的模型, 可能一个模型他是200美元一个月, 第二强或者差一些的模型是50美元一个月, 或20美元一个月, 我们今天发现的就是很多起码美国的人, 他是会愿意花那个溢价去用最好的模型, 因为可能他的零星是20万美元, 他愿意去, 他每天比如要做10个任务, 一个像OPUS这样一个非常强的模型, 他可能会10个任务, 8,9个就直接做对了, 那差的模型他可能做对5,6个, 问题就是说你不知道这5,6个是哪5,6个的情况下, 那你就需要花很多的外经济去监控这个事情, 那其实我觉得无论是人还是模型, 在2B这个市场上就发现了一个很有意思的现象, 那个强的模型和稍微差一点或者弱的模型, 他的分化会变得越来越明显, 我觉得这是第一点观察, 然后第二点观察就是说垂直整合这条路, 和模型应用分层这条路的区别, 我觉得一个比较好的例子可能就是, 比如ChadGB agent, 相对比于比如用cloud或者geminite, 加上像manus这样的应用层的产品, 我觉得一方面就是说, 我觉得过去大家会认为就是说, 当你有这个垂直整合能力, 你就肯定会做得更好, 但起码今天来看并不一定, 首先就是说模型层和应用层需要的能力还是挺不一样, 对于尤其是对2B或者是生产力这样的场景来说, 可能更大的域训练还是一个非常关键的事情, 那这个事情可能对于产品公司确实也很难做, 但是想要把这样一个特别好的模型用好, 或者说这样的模型它有它的溢出能力, 其实也需要在应用层或者说在环境这一层做很多相应的事情, 所以我们会发现其实在QC的应用上垂直整合还是成立的, 无论是TriGBT还是豆包还是各种这样的QC的APP, 模型和产品是非常巧合去紧密迭代, 但对于2B来说这个趋势似乎是相反的, 就是说模型在变得越来越强越来越好, 但是也同样还是会有更多应用层东西想要去利用这样的这个好的模型去在不同的生产力环节, 这是我的两个观察。 我在Follow顺语一个问题, 因为你有了一个新的身份, 就是在中国这个市场上, 那你接下来的你想的这个Bat会是什么, 有哪些鲜明的特点或者关键词吗? 现在能给大家share的吗? 对,我觉得腾讯肯定还是一个2C基因更强的公司, 所以我觉得我们会思考就是说怎么样能够让今天的大模型或者说AI的发展能够更给用户提供更多价值, 但我觉得有很核心的思考就是说, 我们发现很多时候我们的Botnet可能在2C这一端不是更大的模型或者更强的强化学习, 或者更强的模型, 很多时候可能是额外的context和environment。 我最近经常举的一个例子, 比如说我想问我今天该去吃什么, 其实你今天问拆GBD和去年问拆GBD或者明年问拆GBD, 这个事情可能都会很差, 因为这个事情你想要编好不是说你需要更大的模型, 更强的域训练, 更强的强化学习, 更多的这个agent环境或者更多的这个更强的这个solo引擎, 这个问题的Botnet可能是你需要更多的额外的输入或者说我们叫context, 比如说如果他知道今天我其实特别冷, 然后我需要吃点暖和的, 然后我今天在这个范围活动, 可能我老婆在另一个地方, 然后她想吃什么各种各样的这些事情, 其实回答这样的问题, 是更多的Botnet我觉得是额外的context。 比如说我和老婆聊了很多时间, 其实我们可以把这聊天记录从微信转发给棉宝, 或者说把这些额外的输入去用好的话, 我觉得其实反而会给用户带来很多额外的价值, 所以我觉得这是我们对to-see上的思考, 然后我觉得做to-be在中国确实是一个非常难的事情, 就是这些生产力的生产力的革命, 包括现在我们今天很多中国的公司, 其实做coding agent其实也是要去打海外市场, 我觉得这方面的话, 我们会思考怎么去把自己给先服务好, 就是说我觉得像创业公司做比如code agent这个事情, 和大公司做code agent这个事情, 可能一个区别就是说, 作为大公司它本身就已经有很多各种各样的应用场景, 各种各样的需要生产力变得更好的地方, 那如果我们的模型能够在这些地方做得更好, 不仅这个模型它会有自己独特的优势, 不仅我们的公司本身能得到很好的发展, 我觉得很重要一点就是说, 对于真实世界更diverse的场景的数据的捕捉, 我觉得会是一个很有意思的事情, 那比如说像cloud, entropy它是一个创业公司, 包括他们想要去做更多的code agent的数据, 其实就是需要通过各种数据厂商去标这些数据, 然后这些数据厂商它其实是需要利用各种各样的软件工程师去想, 我要去标什么样的数据, 怎么去做, 那这个事情可能最后bottom up就是说, 那你数据公司一共就这么几家, 它一共就招了这么多人, 它可能最终你的diversity是会受限, 但是如果你是一个十万人的公司, 可能会有一些有意思的尝试, 怎么去真的把真实世界的数据给利用好, 而不是仅仅依赖于标注商或者说disculation。 多谢顺宇, 我接下来Q一下俊阳, 你怎么看接下来谦问未来的一个生态位或者分化的一个batt, 因为你后面重点讲了那个全模态的方向, 因为之前阿里云更多比如说在2b很强, 那接下来可能你也提了全模态可能更多2c的, 我不知道这方面是怎么思考。 理论上我是不能评论公司的, 但是我觉得公司也不一定有那么多基因之分, 一代一代的人可能就塑造了这一些公司, 比如说今年顺宇到了腾讯之后, 腾讯可能就是变成一个有着顺宇基因的公司。 接下来这一句其实我也想注入一些比如说我们自己对AGI的理解, 因为我觉得今天2b和2c也好, 我们其实是在服务真实的人类, 所以我们其实想的这个问题是应该怎么让人类世界会变得更好, 就你就算做2c的产品其实也会再分化, 比如说今天我觉得OpenAI已经更像一个平台了, 但是你2c的话你其实最终你要服务真实的这批用户究竟是谁, 那今天可能有很多AI可能会比如说我会更偏向Medical, 更偏向Law,但是它可能是自然形成, 我愿意相信Anthropic它可能不是说今天我觉得Coding真的很厉害, 然后我就Bet on它, 因为我知道他们跟这个Business交流真的非常多, 这个可能也是我们自己做的还不够好的一个点, 虽然我们拥有巨大的优势, 当然也有可能中国SaaS市场跟美国确实是不太一样, 他们确实是非常的频繁的跟客户去进行交流, 那其实就很容易去发现很大的机会, 今天我其实跟美国的很多API厂商聊起来, 其实他们都没有想到Coding的Token消耗量居然会这么大, 其实在中国其实还真的没有那么大的, 就至少从我这边来看, 但是在美国的话它就说基本上全都是Coding, 这个事情我觉得不是所有人都能Bet到的, 今天Anthropic在做更多跟Finance相关的一些东西, 我觉得也是他们自己在跟客户当中去看到这个机会, 所以我觉得可能大家的分化的话可能是自然的分化, 所以我更愿意去相信AGI该做这个事情, 然后顺其自然,这个是我们该做的事情。 多谢,多谢,那个阳强老师,您对分化这个问题。 对,分化的问题, 其实我更想聊一下工业界和学术界的分化, 这个可能是横跨美国和中国, 就说一直以来学术界是一个观望者, 工业界在领头在往前风跑, 搞得现在很多学术界的人也在做工业界的事, 像我们唐杰老师, 所以这是一个好事, 就好像物理学,天体物理学刚刚开始的时候, 是以观测为主, 加利略的望远镜, 然后才出现牛顿, 所以我觉得后面一个阶段, 当我们有了众多的稳定的大模型, 进入一个稳态的时候, 我们学术界应该跟上来, 那学术界跟上来要解决什么问题呢? 工业界可能还没来得及解决的一些问题, 这也是我一直在考虑的问题, 就是说智能上界在哪里, 比方说给你一定的资源, 计算资源或者能源资源, 那么你能做到多好? 可以更细一点, 就比方说我们把这个资源怎么分配, 哪些分配在训练上, 哪些分配在推理上, 其实我很早就做AI, 所以我90年代初就思考过, 就做过一个小实验, 就是说我们如果有一定的投入在记忆上面, 那么这个记忆能够帮助推理多少, 然后这个帮助会不会变成一个反向的, 就是说你记得太多了, 反而你记得噪音会干扰你的推理, 那么有没有一个平衡点, 这些问题我觉得今天还是适用的, 还是一个反门头的问题, 然后我最近也在想另外一个问题, 就是大家学计算机的都必定上一个计算机理论课, 里面有一个重要的定理叫戈德尔的不完备定理, 就是说大概的意思就是一个系统, 就像我们一个大模型, 它是不能自证清白的, 就是说它必定是有一些幻觉是不可能消灭掉的, 那可能你给更多的资源它会消灭的更多, 所以这样科学问题就来了, 就是说你多少资源能换取多少的, 比如幻觉的降低或者错误率的降低, 那么这个是有一个平衡点的, 这个平衡点特别像什么呢, 特别像经济学, 就是经济学的风险和收益的一种平衡, 所以我们这也叫无免费无餐定理, 所以像这些东西我觉得今天就特别适合数学界, 算法界和学术界和工业界一起来做研究, 所以我觉得这是孕育着一个巨大的突破, 然后刚才唐杰老师也提到持续学习, 我觉得持续学习特别好的一个问题是什么呢, 就是它里面有一个时间的概念, 就是你在持续的不断的学的过程当中, 但是你会发现, 比方说你把不同的agent给串联起来, 每一个agent都不能做到百分之百的话, 那么你在N个以后, 它的那个是按指数下降了, 它的那个能力, 那么你怎么样能够保证它不下降, 我觉得人类是用一个方法来做这个事, 我们第一天有学习, 第二天会在第一天的一些噪音的基础上学习, 那么这样你的能力就类似大模型会下降, 但是人类有一个方法就是睡觉,睡眠, 所以我建议大家去看一本书叫我们为什么睡觉, 是一个MIT的两个教授写的, 那个里面就写得非常好玩, 就是Why we sleep, 他说每天晚上睡觉其实是在清理这些噪音, 使得第二天你可以把这个准确率持续的提升, 就不至于是两个错率的叠加, 所以像这些理论的研究孕育着一种新的计算模式, 所以我们今天可能比较关注Transformer, agent computing, 但是我觉得有必要去做一些探索, 新的探索, 这个是我回答你的问题, 就是工业界和学术界要拉齐。 感谢,感谢任强老师。 那个唐老师, 因为我们从那个外部的感受上, 制服今天更像是走了Anthorfic这条路线, 就是Coding非常非常强, 这个榜单上也非常靠前了, 包括您刚才讲的Long-Horizon这种长程的agent, 也是接下来的, 我不知道您对分化这个主题。 我倒觉得就回到一个最本质的问题, 就是早期的时候确实是, 当时我觉得最本质还是做机作模型, 智能上界这可能是最本质的, 但是当时2023年, 我记得是那个时候我们是第一个做出Chat的, 所以当时我们第一个想法, 就是赶紧把Chat扔到网上上线了, 但是当然了, 后来其实结果是国家有相关的统一规定, 就等到八九月份大家一起来上, 但一起来上的时候, 我第一个感受是十来个大模型都上来了, 而且每一家其实用户都没有那么的多, 都没有那么的多, 当然今天分化得更严重, 后来我经过一年的思考, 我觉得其实这个可能它已经, 它不是真的解决问题, 它可能甚至是在我们原来我的第一个预判, 我是说它会替代搜索, 到今天我相信大家很多人在开始用这个模型替代搜索, 但是并没有替代谷歌, 就谷歌其实反而反过来一帐, 把自己的搜索革命了, 就是谷歌自己做了搜索的改进, 所以从这个角度上, 这一帐我觉得自从DeepSec出来之后, 我感觉已经结束了, 就没有了, 这场已经结束了, 那从DeepSec之来之后, 应该思考的是下一个Bit是什么东西, 就下一帐是什么东西, 我觉得下一帐我是年初, 我们当时团队讨论了, 争论了好久, 就是下一帐肯定是要让AI做一件事情, 但做这件事情是什么, 确实可以Bat一下, 而且那个时候其实广密还到我们那儿跟我们交流, 其实广密的那个知识特别圆薄, 他思考问题很深邃, 就他当时的交流对我启发也非常大, 就原来我还没有想到, 但是后来那次确实让我启发非常大, 后来我们团队有几个晚上, 就争论了好多晚上, 争论到最后, 你可以叫我们运气吧, 但另外一方面我们也是Bat, 就是Bat这个Coding, 后来我们就把所有的精力就放在了Coding上, 对,这个就是, 我觉得有Bat是一个特别有意思的, 就是我的一个感受就是过去一年, 中国不仅是开源很强, 而且大家有了自己的Bat, 而且接下来有可能分化更深, 因为不只是大家都在追求通用能力, 但是大家都有自己的资源秉扶, 把擅长的那个点做得更好, 那接下来我觉得有一个, 第二个比较有意思的问题, 就是因为今天这个时间点特别特殊, 一个是预训练过去走了三年, 大家都说可能今天走到了七八成的受益了, 那个RO强化学习, 可能今天大家也都成为共识, 可能走到了比如说四五十的一个空间了, 当然后面空间大家Skill数据, 环境可能空间很大, 那今天硅谷也都在讨论接下来新的一个范式, 就是唐老师刚才也提到叫自主学习, 自我学习, 那个就是我觉得是挺, 因为今天这个会的主题是接下来的展望Next, 我觉得这个是一个特别值得去聊的一个话题, 要不我们先从顺语开始, 那个因为你从领先的OpenEye待过, 就是对于下一个范式, 这个是怎么思考的, 因为OpenEye是一个为人类叫推进了前两个范式的一家公司, 那对第三个范式从你的一个观察来讲, 就是能给大家带来一些分享吗? 对,现在自主学习是一个非常热门的词, 就是在硅谷大街小巷咖啡馆里面大家都在谈论, 就不仅形成了一个共识, 我根据我的观察, 可能每个人对这个东西的定义和看法都不一样, 我讲两点, 我觉得第一点就是说, 我觉得这个事情的Botanic其实不是方法论, 而是数据或者任务, 就是当我们在谈论自主学习的时候, 它到底是在什么样的一个场景下, 基于什么样一个奖励函数去做的, 你在聊天的时候变得越来越个性化, 是一种自主学习, 在写代码的时候越来越熟悉, 每个公司独特的环境或者文档是一种自主学习, 你去探索新的科学, 在这个过程中就像一个博士一样, 从完全不了解有机化学是什么, 到变成这个领域的专家, 这也是一种自主学习, 但我觉得每一种自主学习, 其实挑战或者说方法论可能都不太一样, 然后我觉得第二点就是说, 我不知道这是不是一个非共识, 但我觉得这个事情其实已经在发生了, 对吧,就是说很明显的XIGBT它是在利用这个用户数据, 在不断的理和, 人的聊天的风格是什么, 实际上聊天的感觉越来越好, 对吧,那这是不是一种自主学习, 那今天ClockCode它已经写了ClockCode这个项目的95%的代码, 从不同程度来说, 它在帮助它自己变得更好, 那这是不是一种自主学习, 我记得我们当时2022年23年的时候做CV Agent, 其实我去谷歌AGI House去宣传这个工作, 我当时写了一个第一页Introduction的slide, 就是说这个ASI的最重要的点就是自主学习, 那今天的AI系统其实本质上它都有两部分, 首先它有个Numeric Rectors, 它是一个模型, 其次它有个代码库, 就是你怎么去用这个模型, 是用来做推理还是用来做Agent, 它相应的有个代码库, 就是说我们今天看ClockCode这个系统, 它本质上也有两部分, 一部分是比如Opus这个Neural Network, 另一部分是怎么样去使用这个Neural Network的一大堆相应的代码, 无论是Kernel GPU的还是更往上的部署环境的, 或者说它的前端或者它的Interface应该是什么样子, 当时我想说的点就是说, 其实我们做CV Agent最大的一个初衷就是说, 如果有一天CV Agent能自己去Improve CV Agent Ripple, 那它是不是就是一种AGI, 我觉得今天ClockCode已经在大规模的在做这个事情, 但是可能人们意识不到, 或者说这些自主学习的例子可能还没有, 还在,还局限在每一个特定的场景下, 没有让人感觉到这个非常大的威力, 但我觉得就是说这个事情已经在发生了, 只是说可能它学习的效率, 或者说它受它的场景的限制有各种各样的问题, 那可能这个事情, 我个人的看法是它可能会更像一个渐变而不像一个突变, 当然这个我也很有可能是错的。 对。 我在Follow顺语一个问题, 就是有一些人对自主学习比较乐观, 觉得二六年是能看到一些信号的, 那从你看来, 你觉得自主学习看到信号, 还有哪些实际的问题要突破呢? 比如说Long Context也好, 模型的并行采样也好, 或者其他, 从你看来你感觉接下来还有哪些的关键条件, 具备了这个信号才会发生? 很多人说二六年才能看到一些信号, 但我觉得二五年其实已经有些信号了, 比如说Cursor, 他们现在做的, 他们的Auto-Complete Model, 它其实就是每几个小时就会用最新的用户数据去不停地学习, 包括他们现在新的Composer Model, 其实也是在使用这些真实环境下的数据去训练, 当然大家觉得这个东西可能还没有特别识破天机, 因为他们受限于他们没有预讯的能力, 他们的模型效果确实还不如Opus, 但我觉得这个很显然已经是一个信号了, 我觉得其实最大的Bottleneck是想象力, 我们可以很容易想象, 比如说强化学习或者推理这个范式, 它如果实现大概是个什么样子, 我们可以想象一个O1这样的Blog Post, 我们在数学题上面, 本来是十分,现在变成了八十分, 我通过强化学习有非常长的思维电脑去做这个事情, 但比如说如果26年或者27年我们有一个范式的发生, 一个Blog Post说我宣布了一个新的模型或者新的系统, 它实现了自我学习, 那我们应该用一个什么样的任务, 它应该是什么样的效果, 你会相信它实现的, 比如说它会是一个赚钱的交易系统, 它开始赚很多钱, 就像Winning Bunch的衍生, 还是说它真的解决了一个人类之前没法解决的科学问题, 还是别的, 那我觉得可能先要想象到那个Blog Post是长什么样的, 顺悦, 因为OPAI已经立了两次范式的创新了, 你觉得如果2027年有新的范式出来, 全球范围内你感觉哪一家公司继续立的范式创新的概率最大, 如果说一家公司, 可能OPAI还是会概率更大, 但是我觉得因为它的商业化各种各样的变化, 我觉得它的创新的基因已经被取得了, 但是我觉得它还是最有可能诞生新范式的地方, 多谢顺悦, 俊阳, 你对下一个范式对2027年有什么要展开的? 是不是2026? 那我们就聚焦在2026吧, 如果从更实际一点来讲的话, 可能刚才讲范式也还在比较早期的阶段, 因为今天讲RL这个事情, 实际上我们的RL的Computer还没有scale的那么的充分, 所以很多潜力其实没打出来, 就是今天我们还看到很多Infra这个问题在这里边发生, 但全球范围内我觉得类似的这个问题也都还存在, 但如果要说下一代这个范式的话, 我觉得一个自主学习, 之前跟一个朋友聊到, 就说人类不能让这个AI变得更厉害, 就是比如说你跟这个AI不断的交互, 你只会让它上下文变得越来越长, 然后这个AI只会变得越来越笨, 这个是一个很烦人的事情, 那Test time scaling这件事情是不是真的能够发生, 这个我觉得还是挺值得去思考, 就是说你能托更多的Token, 然后能让你变得更强, 我至少觉得O系列它一定程度上实现了这个事情, 但有没有可能比如说像Tropping说的, 我真的干30个小时是真的能够干出来很难的这个任务, 我觉得今天大家去做那种AI scientist这个事情, 其实还挺有意义的, 因为你在挑战以前很难的, 甚至是做人类未曾做到的这个事情, 有没有可能通过Test time scaling去进行实现, 那么从这个角度上来说的话, AI肯定是需要自主进化的, 但究竟你是不是要更新参数, 这个我觉得见仁见智, 可能大家都有不同的技术手段去实现这个事情, 但我觉得还有第二个点是, AI有没有可能实现更强的主动性, 就说我环境可能就是我的输入的信号, 比如说我现在的AI, 你必须得有人类去prompt它, 然后你才能够启动它, 那有没有可能环境就能prompt它, 自己能自主思考去做一些事情, 但这引发了一个新的问题就是安全的问题, 就我非常担心安全的这个问题是, 其实不是很担心今天他讲一些不该说的话, 最担心的事情是他做一些不该做的事, 就比如说他今天主动的产生一些想法, 往这个会场里边扔一个炸弹这种事情, 我们肯定是不希望这些不安全的事情发生, 但就像培养小孩一样, 我们可能要给他注入一些正确的方向, 但主动学习可能会是挺重要的一个范式。 是的,俊阳又提了一个主动性, 主动性其实也可能是26年非常关键的一个batt, 我在follow俊阳一个问题, 就是如果自主学习26年看到信号, 你感觉可能是在哪些任务上做什么样的任务, 会先看到是模型训练模型了, 最强的模型可以提升自己了, 还是说自动化的AI研究员了, 你有期待在哪些地方先看到吗? 我觉得自动化的AI研究员可能甚至都不是那么需要自主学习, 我觉得可能很快AI训AI这件事情就可以实现, 我看着我们的同学每天在干的这个事情, 我都觉得造得很快就能把他们替代掉, 但是我觉得可能是更持续的理解用户这件事情, 比如说personalization这件事情其实还挺重要的, 就比如说过往我们在做推荐系统的时候, 其实用户这个信息它是持续的输入是会让你整个系统变得更强, 虽然它的算法其实是很简单, 但今天在AI这个时代, 它是不是能够更懂你, 就是你的这些信息的输入是你成为最好, 我们过去讲那个copy了, 但其实今天连copy了都没有实现, 就是能不能真的成为我的copy了这个问题, 所以我觉得如果说自主学习的话, 可能会是在跟人的交互上, 比如说personalization这件事情上可能就能做到, 但是以什么指标来进行衡量, 我觉得稍微有点不太好说, 因为在推荐的时代的话, personalization你做的这个越好的话, 那么别人可能就点的越多买的越多, 但是在AI这个时代覆盖到人类的生活方方面面的时候, 真正的personalization的衡量指标是什么, 我们其实不太知道, 所以今天我感觉可能更大的从技术上的挑战是说, 我们今天的evaluation不知道该怎么做, 这个可能是我们更值得研究的问题。 明白,对,因为你说到了主动,包括个性化, 你感觉如果实现记忆这个点, 这个26年能看到技术的突破性的跨越吗? 我个人观点是大量的技术, 其实所谓的突破性的话都是一些观测问题, 它其实都是在线性的发展, 只是人类对它的感受非常的强烈, 也包括像ChadGPT的出现, 其实对于我们做大模型的来说, 其实就是在线性的增长, 那现在的话大家就是在做memory这个事情, 你说这个技术方案对还是不对呢? 我觉得很多方案也没有什么对错之分, 但是做出来这个效果, 至少我拿我们自己这个献个丑, 就是我们自己的memory呢, 它看起来好像知道我过去干了什么, 但只是记起来过去的这个事情, 每次都会叫一遍我的名字, 但其实并不显得你很聪明, 但你的memory有没有可能到某一个临界点的时候, 让人觉得说, 你结合你的memory真的能够, 就像生活当中的人一样, 过去大家讲这个电影叫HER, HER的话其实它就真的很像这个人, 就理解你的memory, 可能就是在那一下人类的感受就觉得突然间迸发, 那可能就是那一种, 那我觉得多少少也需要一年时间, 很多时候其实我觉得技术也没有发展这么快, 只是大家比较卷, 觉得每天都有这个新的东西, 但其实技术就是在线性的发展, 只是我们可能是在观测的角度, 在处于一个指数上升的这个阶段, 比如说coding能力的一点点提升, 可能就能带来很多的生产价值, 大家可能就觉得AI发展很快, 但从技术的进展上来说, 可能我们就多干一点点这个事情, 因为每天看我们自己做的事情都还真的挺土的, 就解的那些bug就真的都不好意思拿出来跟大家讲, 就非常的丑陋, 那如果这样做我们都已经能够做到这样的成绩的话, 那我觉得可能未来算法的infra结合得更好的话, 可能能更加大有可为。 多谢,多谢君, 那个, 严强老师。 对,我一直以来是做这个联邦学习, 联邦学习的主要思想就是说多个中心大家协作, 那么我现在越来越多的看到很多, 就是有本地资源不足, 但是本地的数据有很多的隐私和安全的要求, 所以这样我们就可以想象, 就是现在大模型的能力越来越强, 那这种通用性大模型和本地的这种特殊性的小模型, 或者是领域专家的模型, 如何协作, 我觉得这种协作变得越来越可能, 像美国我看到zoom就是, 黄学东他们做的叫Federated AI系统, 就是他做了一个很大的一个基座, 这个基座大家都可以插进来, 然后他就可以在一个decentralized状态下, 能够既保护隐私, 又能够和通用大模型有效的沟通协作, 我觉得这种开源模式特别好, 一个是知识的开源, 一个是code的开源模型阶段, 所以我觉得尤其在像医疗金融这样的场景下, 会越来越多看到这样的现象发生。 多谢严谦老师, 联邦学习, 对, 唐老师, 我其实对今年会有比较大的范式革新, 我倒是挺positive的, 我觉得我倒不说太细, 因为那几个点, 就像我刚才讲的, 包括持续学习, 还有memory, 甚至模型架构, 甚至动物态, 我觉得都有可能出现新的范式的变革, 但我觉得一个大的趋势, 我来说一下为什么会产生这样的一个范式, 我觉得原来其实是工业界跑得远远快于学术界, 我记得在去年和前年的时候, 回到清华跟好多老师聊天的时候说, 能不能做大模型, 很多老师是第一没卡, 不是没卡, 是卡的数量几乎为零, 那么工业界是有一万片, 学校是零片或者一片, 那个倍数是一万次, 但是到现在的时候, 很多学校已经有很多卡了, 而且很多老师已经开始做了很多大模型, 包括硅谷那边有很多老师都开始做这种, 甚至模型架构, 持续学习, 这些相关的研究, 所以它已经不是一个, 原来我们都总觉得工业界在dominate这些, 其实今天我觉得在2025年底到2026年初的时候, 我觉得这一现象不大存在了, 可能还有十倍的差, 这里一万片, 那里一千片, 但是它已经孵化出种子了, 我觉得在学术界它有创新的基因, 有这个可能性了, 这是我觉得是第一个, 第二个, 我觉得一个创新的出现, 它一定是某个事情, 它有大量的投入, 并且它的efficiency变成平静了, 那么现在在整个大模型里面投入已经巨大, 但是那个efficiency并不高, 也就是我们继续scaling, 你说有没有收益, 肯定是有收益的, 比如说原来我们data, 你比如从2025年初, 当时可能十个TB的数据, 现在三十个T, 甚至我们可以scaling到一百个T, 但一百个T你scaling上去以后, 你的收益有多少, 还有你的计算cost有多少, 你就变成这么一个问题, 你不创新, 这个就变成一个你可能花掉了十个亿, 花掉了二十个亿, 但是你的收益很小, 就不值得了, 那另外一方面, 对于新的这种智能上去, 假如我们每一次我们都要重训一个基座, 再重训很多RLO, 像24年初那RLO的时候, 大家很多人会觉得我接着训, 它就收益比较的有, 但到今天的时候, 你再记得疯狂的叫RLO, 收益也是有的, 但就没有那么significant, 还是一个收益效率的问题, 就可能我们未来, 也许可以定一个, 一方面我们继续要sgling up, 我刚才其实讲的, 我在台上讲了一个, 我说那是反正最笨的办法就是skilling, 因为skilling我们肯定有收益, 所以这是一个典型的工程做法, skilling肯定会带来智能的上界的提升, 毫无疑问, 你只要get more data, 但是第二个方法, 我觉得应该定一个叫intelligence efficiency, 就是说智能的效率, 我们获得智能的效率, 就是我们用多少的投入, 能获得智能的增量, 如果我们能用更少的获得它增量, 而且我们现在已经变成一个瓶颈了, 假如能用更少的一个范式, 获得同样智能提升, 这个它就变成一个瓶颈式的事情, 所以我是觉得2026年, 一定有这么一个范式的发生, 当然我们也是在battling, 我们也在努力, 我们希望这个发生在我们身上, 但也不一定。 对,我跟唐老师也是一样, 非常乐观的, 因为其实每个领先的模型公司, 每年它的计算量, 实际上是每年compound有十倍左右, 其实大家手上的计算资源多了, 而且人才也涌入的越来越多, 其实大家手上卡片多, 做的实验多了, 其实它就是一个实验工程, 有可能某个点就出来了, 对,刚才唐老师也聊到一个, 怎么衡量智能水平的这个点, 我觉得第三个就是, 我们可以一起聊一下Agent这个战略, 因为最近我跟很多研究员聊, 大家都提到, 对26年还有一个很大的预期, 说Agent今天可以在后台, 比如说推力三到五个小时, 做人类比如说一到两天的工作量, 大家期待说26年可以做人类, 正常你工作个一周到两周的工作量, 那这也是一个非常大的一个变化, 因为它不再只是一个工具, 那个就是唐老师提的说只是一个chat, 而是说真的在自动化你一整天, 甚至一周的这个任务流, 那这样的话其实26年有可能是Agent, 真的就要创造经济价值的关键的一年, 所以Agent这个问题, 我们可以让大家展开聊一下, 因为大家也是顺于刚才提的垂直整合, 既有模型又有Agent的产品, 包括我们看到硅谷的几个公司, 也都从模型到Agent也是端到端都做了, 因为顺宇你花了很多时间做Agent的研究, 你对26年这个Agent, 比如说Long Horizon的这种Agent, 这个真的能automate人类比如说一周到两周的工作, 对Agent的战略, 包括从模型公司的出发点, 会怎么思考这个问题? 我觉得还是像刚刚说的, 我觉得在2C和2B可能不太一样, 目前看起来的话, 我觉得2B的情况就是现在它已经达到了一个不断上升的曲线, 目前看起来好像没有要变慢的趋势, 我觉得按超倍直公司很有意思一点, 它基本上不做什么创新, 它就是觉得你模型预训练变大, 然后老老实实地把R这些东西做好, 然后你只要预训练不断地变大, 后续练不断地就去把这些真实世界的任务给做好, 那它就不断地变大, 然后你只要预训练不断地变大, 所以我觉得它就是会越来越聪明, 它就会带来越来越多价值, 然后按超倍这个公司很有意思一点, 从某种程度来说, 做2B其实你的所有的目标之间是更一致, 你的模型的智能越高, 然后你解决的任务就越多, 你解决的任务越多, 在2B下你带来的收入就越大, 那所有事情就坏了, 那做2C的一个问题就是说, 我们都知道DAU或者说这些产品的指标, 其实是和模型的智能很多时候是不相关的, 或者说甚至有相反的关系, 那我觉得这是按超倍能够聚焦的另一个很重要的原因, 就是说它只要真的把模型越做越好, 那它的收入就越来越高, 所有事情全部都是非常非常aligned, 目前看起来我觉得2B才, 我觉得就是或者说生产力的这种agent才刚刚开始, 很多时候我觉得现在可能除了模型之外有两个bottom neck, 一个是环境问题或者说deployment问题, 我觉得就是说, 我之前在open line之前我在一个叫Cierra的公司实习过, 这是一个2B的客服公司, 我觉得在2B公司工作过还是有很多收获, 我觉得最大的收获就是说, 我感觉即使今天模型不再变好, 就是所有的模型训练全部停止了, 但是我们就是把这些模型去布置到这个世界上各种各样的公司, 那它可能已经能带来今天比如10倍或者100倍的收益, 或者说可能已经对GDP产生一个5%到10%的影响, 当然今天我觉得它对GDP的影响远远不到1%, 我觉得第二点就是说可能教育非常重要, 我观察就是说现在人和人的差距在拉大, 就是因为更多时候不是说AI替代了人的工作, 而是说会使用这些工具的人在替代那些不会使用那些工具的人, 就像当年电脑刚刚差别出来, 你如果去转身去学会学习编程, Versus你还在使用计算尺, 在使用算盘, 那这就差距巨大了, 我觉得可能今天中国能做的一个最大的有意义的事情, 其实就是更好的教育, 教育大家怎么更好地去使用像Clockall或者Chadpy这样的产品, 当然Clockall可能在中国用不了, 但是我们可以用Kimi或者GPU这样国产的模型。 多谢多谢俊阳, 对,agent这个想法, 包括因为千万也有一个生态, 就是说千万自己做agent以及扶持生态的通用agent, 你也可以展开讲讲。 这里可能涉及一个产品哲学的问题, 当然Manus确实很成功, 但是套壳是不是个未来这本身也是个话题, 我觉得今天到这个timing, 我其实比较同意你的观点, 叫模型及产品, 我跟TML的人聊他们那个叫researcher's product, 其实我挺喜欢这个事情, 包括我的视角看openAI, 我觉得还挺多这种事情, 就挺多researcher自己能够成为产品经理, end to end把这个东西给做起来, 包括今天我们自己内部的researcher, 都想做更多面向真实世界的一些东西, 我其实愿意相信说接下来的agent的话, 是可以做到刚才所说的这个事情, 而且跟刚才所提的self-evolvement以及主动学习, 其实都有比较强烈的关系, 比如说他能干这么长这个时间, 他其实自己就得在这个过程中进化, 并且他要决定去干什么东西, 因为他收到的指令是一个非常general的任务, 所以我们现在agent已经开始越来越变的是那种, 托管式的agent, 而不是说我要不断跟你来来回回交互的那种形式, 从这个角度上来说, 他对模型的要求其实是很高的, 就是说模型就是这个agent本身, agent就是这个产品本身, 如果他们都是这个一体化的话, 那么今天也许做基础模型本身也其实也就是在做这个产品, 那从这个角度上来说的话, 我觉得如果不断提升模型能力的上限, 包括test time scaling做上去的话, 他确实能够做到这个事情, 但我觉得还有一个点是跟环境交互有关系, 就我们现在交互的这个环境还不是很复杂, 就这些都还是电脑的这个环境, 我有朋友是做跟AI for science比较相关的, 那AI for science比如说今天你干alpha 4这个事情, 其实你最后干出来它还没有到内部, 就距离比如说举个例子, 比如说制药这件事情, 其实你就算今天用今天的AI, 可能不一定能帮到你那么多, 因为你要去做实实验, 要去做这些事情才能得到反馈, 有没有可能我们未来的AI能够环境复杂到, 可能是真实的人类世界环境, 就指挥这个机器人就去做实实验, 去加快这个效率, 否则的话比如按照现在这个人类的效率, 现在体制非常低的, 我们甚至还要雇佣很多外包, 来去在这个实验环境里面去做实验, 如果能达到这一个点的话, 可能才是我想象当中说人类要做很长时间活, 而不是说仅仅是在电脑当中比如说写个文件这些东西, 这些东西我觉得可能今年很快就可以完成, 但我觉得接下来三年到五年的时间, 可能这个事情可能会更加有意思一些, 那这个的话可能又要跟巨神智能结合在一起了。 我想follow俊阳一个坚韧点的问题, 从你的角度看来通用的agent这个机会是创业者的吗, 还是说模型公司是一个时间问题, 总会把通用agent做好的? 我不能因为我做基础模型, 我就去做创业导师, 我做不了这个事情, 那我只能借成功人士的那句话, 这个pick他说, 他说他做通用agent最有意思的事情就是, 常委反而是更值得关注的这个事情, 或者是说今天AI更大的魅力是在常委, 就是说你如果是马太效应, 你这个头部的这个东西其实挺容易解决的, 当年做推荐的时候, 其实我们就看到那个推荐其实非常集中的商品都是在头部, 但我们其实是想把尾部这个东西推过去, 但是我当时做就非常的遭殃, 我作为一个干NLP和多么太的人, 碰到这个推荐系统, 然后我去干这个解马太效应, 基本上是奔着死路去的, 但我觉得今天的所谓的AGI其实就在解这个问题, 就是说你做通用agent是能不能把这个常委的问题给解决, 就是说今天我一个用户, 我真的寻遍各处我都找不到能够帮我解这个问题的, 但就在那一刻我感受到了AI的能力, 就是全世界任何一个角落我寻遍各处都找不到, 但是你却能帮我解决, 可能这就是AI最大的魅力, 所以你说要不要去做这个通用agent呢? 我觉得见仁见智, 如果你是一个套客高手, 你套的可以比这个模型公司做的更好, 我觉得可以去做, 但如果你没有这个信息的话, 这个事情可能是留给模型公司做这个模型集产品的时候, 因为他们遇到问题的时候, 其实我只要训训模型, 我只要稍稍看, 我可能这个问题就解决了, 所以见仁见智。 其实解决常委的问题, 模型公司就是说算力加数据, 好像你解决下来也挺快的。 今天RL最有意思的地方, 我觉得是我们发现修问题比以前容易, 以前修问题很难, 我举一个B端客户的情况, 他们说我们自己要做SFT, 你能不能告诉我这个通用数据怎么配比, 每次我们都很头痛, 因为我们觉得对方不太会做SFT, 他那个数据就非常的垃圾, 他可能觉得他非常的有用。 今天有了RL之后, 你可能真的很小的一个数据点, 甚至你都不需要这个标注, 你只要有这个query, 有这个reward, 这个东西稍微训训, 然后合并起来其实也非常的容易, 可能是今天技术的魅力。 多谢俊阳, 那个阳枪老师。 对,我觉得agent出现应该有四个阶段, 我们看一个是目标的定义, 是由人为定义的还是自动定义的目标, 第二个是说规划, 就是中间的action, 规划也可以由人来定义, 也可以由AI自动定义, 所以这样就自然分为四个阶段了, 我觉得我们现在在一个非常初级的阶段, 就是目标也是人定义的, 然后规划也是由人来做的, 所以现在的这些agent的definition的软件系统, 基本上是一个更高级的, 一个very high level programming language, 但是我预料未来会出现一个大模型观察人的工作, 然后把人的尤其是这种process data给使用起来, 最后目标也可以是大模型来定义, 然后规划也可以是由大模型来定义, 所以agent应该是由大模型内生的一个native的系统。 多谢,多谢演讲了,唐老师。 我觉得那个agent确实它有几个决定了agent未来的走势, 我觉得第一个就是说这个agent它本身有没有解决人类的一个事情, 而这个事情它是不是有价值的, 而价值有多大, 如果你说比如说原来agent像GPS出来也是做了很多很多agent, 在那个时候其实你会发现那个agent都很简单, 都非常简单, 最后发现primum就解决了, 那这个时候那些大部分agent慢慢就死掉了, 所以我觉得第一个是解决这个agent这个事情它有多有价值, 然后以及真的能不能帮到人, 这是第一个, 第二个就是说白了是做这个事情咱们cost有多大, 就是如果cost特别大, 那这个时候其实也是一个问题, 那刚才其实俊阳也说的, 那也许我调用一个API就能把这个问题解决了, 但是反过来假如调个API就能解决, 那么这个API它本身有可能它觉得当这件事情价值很大的时候, 它就会把它做进去, 它就会把它做进去, 这是个矛盾, 这是个非常矛盾的事, 就机做和应用永远是个矛盾, 最后一个维度就是做应用的速度, 就是你如果说我有个时间窗, 我能够拉开半年的时间窗, 我迅速的把这个应用满足了, 半年以后要么迭代要么怎么着, 反正总之你能往前走, 我觉得这也是一个, 说白了大模型时代到现在, 更多的是在拼速度拼时间, 也许一个决策正确, 就像你刚才说也许我们batt代码正确了, 那也许我们就会在这个方面走得更远一点, 但是也许batt失败了以后就半年就没了, 所以今年我们只是在coding在agent这块, 我们batt了一点点, 所以我们还现在我们coding啊, 调能量这些都还不错, 所以我觉得也更多的也是一个batt吧, 做agent可能未来也是一个batt。 多谢多谢, 因为过去模型公司既要追通用能力, 可能它在优先级上就没有花那么多精力去探索, 其实那个通用能力追上来之后呢, 其实我们也更多的期待26年这个制谱, 前后有更多自己的cloud code时刻和minus时刻, 我觉得这个是非常值得去预期的吧。 因为第四个问题也是最后一个问题, 我觉得比较有意思, 就是因为这个活动包括这个时间点, 我觉得是更多值得去展望真的未来。 就是我其实挺想问大家一个问题, 就是在三年和五年以后, 全球最领先的AI公司是一个中国团队的概率有多大, 然后我们从今天的一个跟随者变成一个未来的引领者, 这个文化包括关键条件, 到底是还有哪些需要去做好的, 就是未来三到五年, 我在想这个概率有多大以及需要哪些关键条件, 因为顺宇, 因为你是经历过硅谷跟中国两个体感的, 你对这个概率的判断和需要哪些关键条件的判断是怎么样的? 对, 这个我觉得概率还挺高的, 我还是挺乐观的, 因为目前看起来就是说, 任何一个事情它既然, 就它一旦被发现出来, 就在中国都会很快地做的, 就是能够去catch up或者说能够去复现, 然后能够去在很多局部去做得更好, 我觉得这个事情, 就包括之前制造业, 电动车这样的例子已经不断地发生, 我觉得可能几个比较关键的点, 一个可能是中国的光刻机到底能不能突破, 如果最终算力变成了bottom neck, 我们能不能解决这个算力问题, 算力目前看起来就是说, 我们有很好的电力优势, 我们有很好的基础设施的优势, 可能主要的瓶颈一个就是产能, 包括光刻机以及这个软件生态, 但如果这个问题解决, 那我觉得会是个很大的帮助, 我觉得可能另一个问题就是, 除了2C之外, 能不能有个更成熟或者更好的2B的市场, 或者说可能有没有机会在国际的商业环境去竞争, 因为今天我们看到很多做生产力或者做2B的这些模型或者应用, 它还是会诞生在美国, 因为那些支付意愿更强, 那些2B的文化更好, 在中国今天, 在中国内做这个事情很难, 所以大家都会选择出海或者做国际化的事情, 我觉得这两个可能是比较大的客观上的约束, 我觉得可能还有个更重要的是主观上的这个概念, 就是说, 我最近因为也在跟很多人聊天, 我之前的感受就是说, 在中国其实有非常非常多非常强的人才, 然后任何一个事情只要它被证明地做出来, 很多人都会去非常积极地去尝试, 并且想要甚至做得更好, 但我觉得今天中国还是, 就这种想要破新的范式, 或者做这种非常冒险事情的人, 可能还是不够多, 当然就这里面可能有经济环境, 商业环境, 包括文化的因素, 但是我觉得可能如果分家一点的话, 就是主观上能不能有没有更多, 就是有这种创业精神或者冒险精神的人, 真的想要去做这种前沿探索, 或者新的范式突破的事情, 因为目前来看, 一个范式一旦没发生, 那我们可以用很少的卡, 很高的效率去Catch Up, 或者说甚至局部做得更好, 但是我们到底能不能去引领新的范式, 我觉得这可能是今天中国, 唯一要解决的问题, 因为其他所有事情, 无论是商业还是产品设计, 还是这种Catch Up做工程, 我们都已经比美国做得更好。 我在Follow顺语一个问题, 你对中国的这个Lab里面的研究文化, 有什么要呼吁的吗? 因为其实你感受过Opan也好, 或者说这个One區的DeepMind这种研究文化, 就中国的这个研究文化跟美国的这个研究文化, 有什么差异的地方? 就是你感觉包括这个研究文化, 对作为一个AI Native的公司, 有哪些根本性的影响? 你对这个有呼吁或者建议的吗? 对,我觉得每一个地方的研究文化都很不一样, 可能比如美国不同实验室之间的区别, 可能比中美之间的区别还要大, 在中国也一样。 我个人觉得可能有两点吧, 一点就是说, 我觉得在中国大家还是更喜欢做, 更安全的事情, 比如说今天预讯的这个事情已经被证明可以做出来了, 那这个事情其实也非常难做, 有很多技术问题要解决, 但是只要这事情一旦被证明能做出来, 那我觉得我们都很有信心, 就是说几个月或者一段时间内就把这东西搞清楚, 然后去决定。 但是如果今天要让一个人说, 我跟你说要探索一个比如长期记忆或者说持续学习, 然后这个事情大家也不知道怎么做, 能不能做起来, 那这个的话我觉得还是比较困难, 但当然的话我觉得可能也不只是说, 大家更喜欢做确定性的事情, 不太愿意做这种创新的事情, 我觉得也有很重要一点, 就是说文化的极美以及整体的认知, 其实是一个需要时间承接的事情, 我觉得, 对,就是可能真的就是说, 在OpenAI比如说做RL这个事情, 它可能是22年就开始做了, 那国内可能是24年就开始做, 那对这个东西的理解可能会有一些差异, 或者说中国的RL没有Skillup这么大, 那我觉得可能很多也是时间问题的, 就是说当你记得文化或者底蕴根深, 从某种浅一模化的程度可能会影响人的做事方式, 但是它很微妙, 我觉得很难通过这些榜单这些东西去体现, 当然就是说到榜单, 我觉得第二点我想要留意的观察, 就是说我觉得中国大家还是对于刷榜, 或者说这些数字会看得更重一些, 我觉得这一点上我觉得可能像Anshabek, 我觉得可能就会做得比较好, 就是包括我觉得可能DeepThick做得也比较好的一点, 就是说他们可能没有那么关注这个榜单的数字, 可能会更注重就是说第一什么是正确的事情, 第二是什么是你自己体验能体验出来好还是不好, 我觉得这个还是挺有意思的, 就是说因为你看Cloud的模型, 可能在很多编程或者软件工程的榜单上可能也不是最高, 但是大家都知道这个东西是最好用的, 我觉得这个还是需要大家能够去走出这些榜单的束缚, 能够去坚持自己觉得什么是正确的或者什么是好, 多谢多谢盛宇,俊阳,概率和条件。 你这个问题本身是一个危险的问题, 理论上这个场合是可以泼冷水的, 但是如果从概率上来说的话, 我可能想说一下中国和我感受到的美国的差异, 比如说美国的Computed, 可能整体比我们大概一到两个数量级, 但是我看到不管是OpenAI还是Metropic, 他们大量的Computed投入到下一代的research当中去, 我们今天相对来说捉襟见肘, 光交付的话可能就已经占据了我们绝大部分的Computed, 这个会是一个比较大的差异在这里边, 这可能是一个历史以来就有的问题, 创新是发生在有钱的人手里还是穷人的手里, 穷人不是没有机会, 因为我们觉得这些富哥真的很浪费卡, 他们在训这么多东西, 可能训了很多也没什么用, 但今天穷的话, 你其实会想, 比如说你今天所谓的算法, Infra联合优化这个事情, 其实如果你真的很富的话, 你真的没有什么动力去做这个事情, 我觉得可能更进一步的, 刚才顺眼也提到广客级的这一个问题, 未来有可能还有一个点是, 如果从软硬结合的角度, 是不是真的有可能N2N的做出来, 比如说我们下一代的模型结构和芯片, 其实都有可能是一起把它给做出来的, 我特别记得我在2021年的时候, 当时我们在做大模型, 因为阿里做芯片, 然后就来找我说, 能不能预测一下三年之后, 这个模型是不是Transformer, 三年之后这模型是不是多模态, 为什么是三年呢, 他说我们需要三年的时间才能流片, 我当时给大家回答是, 三年之后在不在阿里巴巴我都不知道, 但最后我今天还在阿里巴巴, 然后它果然还是Transformer, 它还是多模态, 我就非常地懊悔, 为什么当时没有去催它去做, 但当时我们这个交流其实非常鸡同鸭讲, 他给我讲了一大堆东西我完全听不懂, 然后我给他讲他也不知道我们在做什么, 就错过了这个机会, 但这个机会有没有可能再来一次, 我们虽然是一群穷人, 但是是不是有可能穷则生变, 那我觉得比如说创新的机会可能是发生在这里, 但我觉得可能我们需要改变的是, 比如说我觉得今天我们的教育在变好, 因为我感受比如说我属于90年代靠前一些, 顺宇宙属于90年代靠后一些, 我们团队里面好多00后, 我就感觉大家这个冒险精神变得越来越强, 当然美国人他天然有非常强烈的冒险精神, 一个很典型的例子就是当时这个电动车刚出来的时候, 甚至这个天篷会漏水的情况下, 甚至可能你开车它可能会意外生亡的情况下, 一样有很多富豪们他都愿意去做这个事情, 但在中国我相信富豪们是不会去干这个事情, 大家会做一些很安全的事情, 但今天大家的冒险精神开始变得更好, 中国的比如说营商环境也在变得更好的情况下, 我觉得是有可能带来一些创新的, 概率没那么大,但真的有可能。 如果派一个数字呢? 你说百分之多少? 对,三年到五年后, 最领先的那个公司是一家中国公司的概率。 我觉得比落百分之二十吧, 我觉得百分之二十已经非常的乐观了, 因为这里真的有很多历史积淀的原因在这里。 我再follow一个问题, 就是你内心的比如说中国的模型跟美国的模型, 这个差距,它这个dynamic变化, 有的地方在追上来,有的地方他们的算力又在拉大, 你内心这个gap变大的恐惧感强吗? 今天你干这一行就不能恐惧, 必须得有非常chill的心态。 从我们心态上来说就是能干这一行已经非常不错了, 就是能够做大模型这件事情已经非常的幸运了。 那就是说我觉得还是看你的初心是什么, 因为其实刚才顺宇提到一个点说, 你的模型可能不一定那么强, 在C端的里边其实是ok的。 我可能转换成另外一个角度去思考这个问题是, 我们的模型为人类社会带来什么样的价值。 只要我去相信我这个东西能够为人类社会带来充分的价值, 能够帮助人类的话, 它就算不是最强的我也愿意接受。 多谢君, 杨老师, 因为您经历过很多AI的周期, 也看过很多中国AI的公司变成世界最强吗? 您对这个问题的判断。 我们可以回顾一下互联网的发展, 一开始也是从美国开始, 但是中国很快就赶上了, 而且应用像微信就是世界第一的。 所以我想AI的话是一个技术, 它是一个enabling的技术, 它并不是一个终端的产品。 但是我们中国有很多的聪明材质, 会把这个产品发挥到极致, 不管是2B还是2C, 但是我可能更看好2C, 因为百化齐放, 中国人群思广益。 但是2B可能有一些具体的限制, 像付费医院、企业文化等等, 这些可能也在改变。 但是我最近也特别的观察一些商业, 方便跟商学院的一些同学探讨。 比方说美国有一个公司叫Palantir, 它的一个理念就是说, 不管AI现在发展到什么阶段, 我总是能在AI里面发现一些好的东西, 应用在企业上。 那么中间肯定是有gap, 我们要给它拟合, 它有一个办法叫本体, 它用一个本体的方法。 其实我观察了一下, 大概的思想就是我们以前做的迁移学习, 就是说把一个general solution 能够用到一个具体的实践当中, 用一个本体来做一个知识的迁移, 这个方法非常的巧妙。 当然它是通过一种工程的方法, 叫前端工程师FDE来解决的。 不管怎么样, 我觉得像这种就非常值得我们学习。 我觉得中国的企业像AI native的公司, 应该发展出这样的一些to be的solution来, 我相信会的。 所以我觉得to see肯定是百花齐放的, to be可能也会很快的跟上来。 多谢杨老师,汤老师。 首先我觉得确实也要承认, 在中美, 我觉得无论从研究, 尤其是企业界的AI lab, 我觉得和美国是有差距的, 这是第一个。 但我觉得也是在未来中国, 其实现在慢慢变得越来越好, 尤其是90后,00后这一代起来, 我觉得慢慢变得真的是远远好过之前。 我有一次在有一次Yorkself的一个会上, 我说过一句话, 我说我们这一代是最不幸的, 他说为什么呢? 我说我们这一代, 其实你看我们上一代还在, 我们现在还上一代也在继续工作, 我们也在工作, 所以我们还没有出头之日, 然后很不幸的下一代已经出来了, 现在世界已经交给下一代了, 已经把我们这一代无缝的给跳过了, 那其实开玩笑的。 但我觉得最有意思的是什么呢? 我觉得可能未来中国也许的机会吧, 第一个就是一群聪明人真的敢做特别冒险的事, 我觉得现在是有的, 现在是有的, 00后这一代包括90后这一代是有, 包括俊阳,kimi,还有顺宇这些都是愿意, 而且非常感愿意冒风险来做这样的大冒险的事, 我觉得第二个倒是确实是咱们的, 可能这个环境要更好一些, 无论从国家的环境, 就是我的意思是说, 比如说大企业和小企业之间的竞争, 那创业企业之间的一些问题, 还有包括我们的营商环境, 比如说像刚才俊阳说的我还在做交付, 其实这些都我觉得把这个环境如果比较的更好, 让大家一群聪明人, 又敢于冒险的聪明人, 有更多的时间去做这样创新的事情, 比如说让俊阳这样的去做, 有更多时间来做创新的事情, 我觉得这是第二个, 也许是我们政府包括我们国家可以来帮忙改善的一个事情, 第三个我倒觉得是回到我们每一个人自己身上了, 就是我们能不能坚持, 就是我们能不能愿意在一条路上, 我们敢做, 我们敢冒险, 而且环境也还不错, 是吧, 我觉得环境肯定不会是最好的, 永远不要想环境是最好的, 我觉得我们恰恰可能也是幸运, 我们在经历一个环境从也许原来可能没那么好, 慢慢变得更好的一个时代, 我们是经历者, 也许就是财富, 包括经历收获最多的人, 如果我们笨笨的坚持也许走到最后的就是我们, 感谢大家。 感谢, 感谢汤老师, 所以我们也很想呼吁说, 应该更多的资源资金投入到中国的AGA行业, 有更多的算力, 然后让更多的AI的年轻的研究员戳卡, 就是有可能戳个三五年, 中国也有三五个自己的Eliya, 这是我们未来三五年很期待的, 感谢大家。 非常感谢, 好, 感谢大家。 接下来邀请张院士来对今天有一个压轴的电评, 对。
